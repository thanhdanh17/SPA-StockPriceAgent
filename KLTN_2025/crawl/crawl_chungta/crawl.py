from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import requests
import json

# âš™ï¸ Cáº¥u hÃ¬nh Selenium Chrome
chrome_options = Options()
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")
# chrome_options.add_argument("--headless")  # Bá» comment náº¿u muá»‘n cháº¡y áº©n

driver = webdriver.Chrome(options=chrome_options)
driver.get("https://chungta.vn/kinh-doanh")
wait = WebDriverWait(driver, 10)

# ğŸ” Báº¥m "Xem thÃªm" Ä‘á»ƒ táº£i thÃªm bÃ i
for _ in range(1000):
    try:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        button = wait.until(EC.element_to_be_clickable((By.ID, "load_more_redesign")))
        button.click()
        time.sleep(4)
    except:
        print("KhÃ´ng thá»ƒ click hoáº·c Ä‘Ã£ háº¿t bÃ i.")
        break

# ğŸ“„ Láº¥y HTML sau khi Ä‘Ã£ báº¥m háº¿t bÃ i
soup = BeautifulSoup(driver.page_source, "html.parser")
driver.quit()

articles = soup.select("h3.title-news a")
print(f"TÃ¬m tháº¥y {len(articles)} bÃ i viáº¿t.")

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

results = []

# ğŸ” Truy cáº­p tá»«ng bÃ i viáº¿t
for a in articles:
    title_preview = a.get_text(strip=True)
    link = "https://chungta.vn" + a.get("href")

    try:
        res = requests.get(link, headers=headers, timeout=10)
        article_soup = BeautifulSoup(res.text, "html.parser")

        time.sleep(2)

        # TiÃªu Ä‘á» chi tiáº¿t
        title = article_soup.select_one("h1.title-detail")
        title = title.get_text(strip=True) if title else title_preview

        # Thá»i gian Ä‘Äƒng
        date = article_soup.select_one("span.time")
        date = date.get_text(strip=True) if date else "KhÃ´ng rÃµ ngÃ y"

        # MÃ´ táº£
        lead = article_soup.select_one("p.lead-detail")
        lead_text = lead.get_text(strip=True) if lead else ""

        # Ná»™i dung chÃ­nh
        body = article_soup.select_one("article.fck_detail.width_common")
        content = body.get_text(separator="\n", strip=True) if body else "KhÃ´ng cÃ³ ná»™i dung"

        results.append({
            "title": title,
            "date": date,
            "link": link,
            "description": lead_text,
            "content": content
        })

        print(f"âœ… Crawled: {title}")

    except Exception as e:
        print(f"âŒ Lá»—i khi láº¥y bÃ i {link}: {e}")

# ğŸ’¾ Ghi dá»¯ liá»‡u ra file
with open("chungta.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ‰ ÄÃ£ lÆ°u {len(results)} ")
