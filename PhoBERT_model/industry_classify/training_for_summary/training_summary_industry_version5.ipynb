{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12570609,"sourceType":"datasetVersion","datasetId":7938429}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":29602.870154,"end_time":"2025-07-22T00:52:56.552632","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-21T16:39:33.682478","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"02d46ca0697c436baaa5dc8b304a8a85":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2379cf5b9840389ad7d0c72b07f180":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_81bf40ec056b4170b3eb78dc66db140b","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_360c535f9d0b4bdb847cd311d61bceb5","tabbable":null,"tooltip":null,"value":557}},"0c3129bef58b46c7951a3a1025c5da27":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_80644f67f2334d3bbdb50a3a6995f8bc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8956fa8c4bc41d39e45e0d398b1fa6b","tabbable":null,"tooltip":null,"value":1}},"1181d971fa224552914fe772044fa233":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"12d37f2eb85243ddbac820c12eccd224":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15817ea3e48a44f8b541424cd50715b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"15a070a9e7874896a6d7e17bd8d78a11":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_25f0d582e3064aae813e03878e177b55","placeholder":"​","style":"IPY_MODEL_e82d6e79760140b5b9a5adb28681a61d","tabbable":null,"tooltip":null,"value":" 557/557 [00:00&lt;00:00, 44.6kB/s]"}},"16add7735ea6481daf5712009790aec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_68132b5de03e42628e021b0e39210059","placeholder":"​","style":"IPY_MODEL_c0c15cabf7b04700aca7c24c23b592a1","tabbable":null,"tooltip":null,"value":" 543M/543M [00:02&lt;00:00, 286MB/s]"}},"1821652445ac43838887b72b7e2ef125":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"186df3bee9944e35aafa6af91a4c4f24":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f0d582e3064aae813e03878e177b55":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"301470210d56460bab8a70c7bedcab79":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"360c535f9d0b4bdb847cd311d61bceb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3abf70eafd814b249cc1582780b30428":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe02bf6866442199dcac0fc0bdf4b95":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424160e3b8a64cdb84347e9554bfdfb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1c8f521a3894edd84b7c2126420b696","IPY_MODEL_0a2379cf5b9840389ad7d0c72b07f180","IPY_MODEL_15a070a9e7874896a6d7e17bd8d78a11"],"layout":"IPY_MODEL_baf22fa5a69b46e89348f6ef4e00cd92","tabbable":null,"tooltip":null}},"46526b1672724c75a684c576e17ed6ea":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46de8fb370fe4ec18abd3c4bf25b0ef8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4f89bdb62eff47828c30a71b16bb0189":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"526ed076c12a4e08bd64294d7b6c8092":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bfe3914ad55e4e4d9ae999eb7a44cf6d","placeholder":"​","style":"IPY_MODEL_46de8fb370fe4ec18abd3c4bf25b0ef8","tabbable":null,"tooltip":null,"value":" 543M/543M [00:02&lt;00:00, 244MB/s]"}},"58c7f6fb96a8421092c0fe7140bd9954":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5c0d438a013e44499d10f97580d9b998":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5c6732cc192a4efba2816456ad216137":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d55b39af7fb41e29542bf988f95de4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"68132b5de03e42628e021b0e39210059":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73db24063ea84ca4b1f8af238ee7e0f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_02d46ca0697c436baaa5dc8b304a8a85","placeholder":"​","style":"IPY_MODEL_94c86f9881e94a40af79d65fb9dba6d8","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"7543a57cbcea4d8ab6c0fcff8c256c20":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f9c1becfd8e84c968665a7eb6f790cc3","placeholder":"​","style":"IPY_MODEL_15817ea3e48a44f8b541424cd50715b2","tabbable":null,"tooltip":null,"value":"vocab.txt: "}},"779b4801b84f4c1bbee3f214156c1c7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78a31d15f7744edaa9a1e3d6ea439059":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d67057ef754798b005b702ad9e3471":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b80c18ac26344dab43297d18a2a711a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_1181d971fa224552914fe772044fa233","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca4c4ef1a8044623925c32caea207752","tabbable":null,"tooltip":null,"value":1}},"7cb951b23b3044439f4294a075c52f22":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"802bf843166645e38e0761ff17fce295":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80644f67f2334d3bbdb50a3a6995f8bc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"81bf40ec056b4170b3eb78dc66db140b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c1c7e20afc4753842a68d2f67ea948":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8aca01eae84f43a09373ff9b29edddfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f77b3b7ab3b64c38992cffbd61ae6204","IPY_MODEL_ac1d789dffbc4db5a0e51e3e98b48132","IPY_MODEL_16add7735ea6481daf5712009790aec5"],"layout":"IPY_MODEL_add40ce7221a47228180c5cf048ac43d","tabbable":null,"tooltip":null}},"8c0af056d3214f9a9dc6abeef4984a6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_12d37f2eb85243ddbac820c12eccd224","placeholder":"​","style":"IPY_MODEL_89c1c7e20afc4753842a68d2f67ea948","tabbable":null,"tooltip":null,"value":" 1.14M/? [00:00&lt;00:00, 52.9MB/s]"}},"94c86f9881e94a40af79d65fb9dba6d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"962a905bb2c2437b8a8cae9ed3154a73":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97bbf9a90c1044ed8e61e26c1c751339":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d30eec3740114270b7ecc2e2ccc92f11","IPY_MODEL_d33f7de07a4b4107a2c9e7c9541bf0ab","IPY_MODEL_8c0af056d3214f9a9dc6abeef4984a6b"],"layout":"IPY_MODEL_78d67057ef754798b005b702ad9e3471","tabbable":null,"tooltip":null}},"a1c8f521a3894edd84b7c2126420b696":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3abf70eafd814b249cc1582780b30428","placeholder":"​","style":"IPY_MODEL_4f89bdb62eff47828c30a71b16bb0189","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"a7b1e6cce2744834a2e33ffe64409320":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ac1d789dffbc4db5a0e51e3e98b48132":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_46526b1672724c75a684c576e17ed6ea","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb56bc6d2d2646b2a99221967e18221a","tabbable":null,"tooltip":null,"value":542923308}},"add40ce7221a47228180c5cf048ac43d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6d64e8d52834fc4a4a495ad08b17960":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf22fa5a69b46e89348f6ef4e00cd92":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfe3914ad55e4e4d9ae999eb7a44cf6d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c00a6fa7c7bf47d6a85bed784139cd6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3fe02bf6866442199dcac0fc0bdf4b95","placeholder":"​","style":"IPY_MODEL_58c7f6fb96a8421092c0fe7140bd9954","tabbable":null,"tooltip":null,"value":" 895k/? [00:00&lt;00:00, 20.7MB/s]"}},"c0c15cabf7b04700aca7c24c23b592a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c2cf6fdb92fc4653bb80d6ca700b9f36":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_db85ad232ec34a1c814f1b207b5c139d","placeholder":"​","style":"IPY_MODEL_5d55b39af7fb41e29542bf988f95de4e","tabbable":null,"tooltip":null,"value":" 3.13M/? [00:00&lt;00:00, 98.9MB/s]"}},"c32e84af85864c6abc617f0c0d517989":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_301470210d56460bab8a70c7bedcab79","max":542900336,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1821652445ac43838887b72b7e2ef125","tabbable":null,"tooltip":null,"value":542900336}},"c4f551dfade04a67acd33f65296a15d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_962a905bb2c2437b8a8cae9ed3154a73","placeholder":"​","style":"IPY_MODEL_a7b1e6cce2744834a2e33ffe64409320","tabbable":null,"tooltip":null,"value":"tokenizer.json: "}},"ca4c4ef1a8044623925c32caea207752":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d30eec3740114270b7ecc2e2ccc92f11":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_802bf843166645e38e0761ff17fce295","placeholder":"​","style":"IPY_MODEL_5c0d438a013e44499d10f97580d9b998","tabbable":null,"tooltip":null,"value":"bpe.codes: "}},"d33f7de07a4b4107a2c9e7c9541bf0ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e1ccb1ae1eeb45a28facb9c1420e3afa","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_779b4801b84f4c1bbee3f214156c1c7d","tabbable":null,"tooltip":null,"value":1}},"db85ad232ec34a1c814f1b207b5c139d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa8818ada1c43b5a9ababf0261c19dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7543a57cbcea4d8ab6c0fcff8c256c20","IPY_MODEL_0c3129bef58b46c7951a3a1025c5da27","IPY_MODEL_c00a6fa7c7bf47d6a85bed784139cd6d"],"layout":"IPY_MODEL_b6d64e8d52834fc4a4a495ad08b17960","tabbable":null,"tooltip":null}},"e01b9b95d9524c539171a01e88bfd4a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4f551dfade04a67acd33f65296a15d8","IPY_MODEL_7b80c18ac26344dab43297d18a2a711a","IPY_MODEL_c2cf6fdb92fc4653bb80d6ca700b9f36"],"layout":"IPY_MODEL_78a31d15f7744edaa9a1e3d6ea439059","tabbable":null,"tooltip":null}},"e1ccb1ae1eeb45a28facb9c1420e3afa":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e33a64b267c44876b38e500a9b41c82e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73db24063ea84ca4b1f8af238ee7e0f0","IPY_MODEL_c32e84af85864c6abc617f0c0d517989","IPY_MODEL_526ed076c12a4e08bd64294d7b6c8092"],"layout":"IPY_MODEL_186df3bee9944e35aafa6af91a4c4f24","tabbable":null,"tooltip":null}},"e82d6e79760140b5b9a5adb28681a61d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e8956fa8c4bc41d39e45e0d398b1fa6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb56bc6d2d2646b2a99221967e18221a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f77b3b7ab3b64c38992cffbd61ae6204":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5c6732cc192a4efba2816456ad216137","placeholder":"​","style":"IPY_MODEL_7cb951b23b3044439f4294a075c52f22","tabbable":null,"tooltip":null,"value":"pytorch_model.bin: 100%"}},"f9c1becfd8e84c968665a7eb6f790cc3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ccd191f5-d5e8-4ed2-b110-662d2452ea08","cell_type":"markdown","source":"# *Vietnamese News Industry Analysis with PhoBERT*\n## This notebook fine-tunes PhoBERT for classifying industry of Vietnamese news summaries.\n* Dataset: 12007 samples fix","metadata":{}},{"id":"20dfa5a8","cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:28:06.569020Z","iopub.execute_input":"2025-07-25T03:28:06.569394Z","iopub.status.idle":"2025-07-25T03:28:06.691856Z","shell.execute_reply.started":"2025-07-25T03:28:06.569368Z","shell.execute_reply":"2025-07-25T03:28:06.690853Z"},"papermill":{"duration":0.125788,"end_time":"2025-07-21T16:39:38.160381","exception":false,"start_time":"2025-07-21T16:39:38.034593","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"11f36296","cell_type":"code","source":"# Install required packages\n!pip install transformers\n!pip install pyvi\n!pip install pandas\n!pip install seaborn\n!pip install matplotlib\n!pip install scikit-learn\n!pip install torch\n!pip install openpyxl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-07-25T03:28:06.694254Z","iopub.execute_input":"2025-07-25T03:28:06.694557Z","iopub.status.idle":"2025-07-25T03:29:45.705246Z","shell.execute_reply.started":"2025-07-25T03:28:06.694522Z","shell.execute_reply":"2025-07-25T03:29:45.704174Z"},"papermill":{"duration":97.639556,"end_time":"2025-07-21T16:41:15.802120","exception":false,"start_time":"2025-07-21T16:39:38.162564","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\nCollecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->pyvi) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","output_type":"stream"}],"execution_count":2},{"id":"5b887e83-534e-4a10-9eac-2ee1b8d872b9","cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pyvi import ViTokenizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import (\n    classification_report, \n    confusion_matrix, \n    accuracy_score, \n    balanced_accuracy_score,\n    f1_score,\n    roc_auc_score,\n    roc_curve, \n    precision_recall_curve,\n    auc,\n    average_precision_score,\n    cohen_kappa_score,\n    matthews_corrcoef,\n    log_loss,\n    hamming_loss,\n    jaccard_score,\n    top_k_accuracy_score\n)\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.utils import resample\nimport logging\nfrom datetime import datetime\nimport unicodedata\nimport zipfile\nfrom IPython.display import FileLink, display\n\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:45.706661Z","iopub.execute_input":"2025-07-25T03:29:45.707008Z","iopub.status.idle":"2025-07-25T03:29:53.853026Z","shell.execute_reply.started":"2025-07-25T03:29:45.706965Z","shell.execute_reply":"2025-07-25T03:29:53.852464Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"92d64bd0-05e6-450a-900b-d96a3c22880c","cell_type":"code","source":"# Set up logging\nlog_dir = '/kaggle/working/'\nos.makedirs(log_dir, exist_ok=True)\nlog_file = os.path.join(log_dir, 'training_industry_classification_log.txt')","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:53.853672Z","iopub.execute_input":"2025-07-25T03:29:53.854042Z","iopub.status.idle":"2025-07-25T03:29:53.858054Z","shell.execute_reply.started":"2025-07-25T03:29:53.854022Z","shell.execute_reply":"2025-07-25T03:29:53.857357Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"2cf1556f-1d3d-4e39-b0b2-a97fd573f666","cell_type":"code","source":"# Remove existing log file if it exists\nif os.path.exists(log_file):\n    try:\n        os.remove(log_file)\n    except Exception as e:\n        print(f\"Could not remove existing log file: {e}\")","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:53.858958Z","iopub.execute_input":"2025-07-25T03:29:53.859275Z","iopub.status.idle":"2025-07-25T03:29:53.877952Z","shell.execute_reply.started":"2025-07-25T03:29:53.859250Z","shell.execute_reply":"2025-07-25T03:29:53.877259Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"1868b278-f554-4674-9772-1037e7956d3f","cell_type":"code","source":"# Configure logging\ntry:\n    logging.getLogger().handlers.clear()\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setLevel(logging.INFO)\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.WARNING)\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n    logging.basicConfig(\n        level=logging.INFO,\n        handlers=[file_handler, console_handler],\n        force=True\n    )\n    logging.info(\"Logging initialized successfully\")\n    print(f\"Log file will be saved to: {log_file}\")\nexcept Exception as e:\n    print(f\"Failed to initialize logging to file: {e}. Using console logging only.\")\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[console_handler]\n    )","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:53.878649Z","iopub.execute_input":"2025-07-25T03:29:53.878895Z","iopub.status.idle":"2025-07-25T03:29:53.888489Z","shell.execute_reply.started":"2025-07-25T03:29:53.878877Z","shell.execute_reply":"2025-07-25T03:29:53.887731Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Log file will be saved to: /kaggle/working/training_industry_classification_log.txt\n","output_type":"stream"}],"execution_count":6},{"id":"dc86d85f-8e13-4eda-af31-a22575fe8b15","cell_type":"code","source":"# Seed everything for reproducibility\ndef seed_everything(seed_value):\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed_everything(86)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Configuration\nMAX_LEN = 256 \nN_SPLITS = 3","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:53.890967Z","iopub.execute_input":"2025-07-25T03:29:53.891209Z","iopub.status.idle":"2025-07-25T03:29:53.993035Z","shell.execute_reply.started":"2025-07-25T03:29:53.891193Z","shell.execute_reply":"2025-07-25T03:29:53.992278Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"30a52f25-aef5-45a7-8fb0-87ddf8b56569","cell_type":"code","source":"# Phase 1: Load Data\ndef load_original_data(xlsx_path):\n    original_df = pd.read_excel(xlsx_path)\n    df_processed = original_df[['summary', 'industry']].copy()\n    logging.info(f\"Original data loaded with shape: {original_df.shape}\")\n    assert original_df.equals(pd.read_excel(xlsx_path)), \"Original data modified!\"\n    return df_processed\n\n# Phase 2: Data Cleaning\ndef clean_data(df):\n    nan_rows = df[df['summary'].isna() | df['industry'].isna()]\n    if not nan_rows.empty:\n        df = df.dropna(subset=['summary', 'industry'])\n        logging.info(f\"Removed {len(nan_rows)} rows with NaN values\")\n    initial_rows = len(df)\n    df = df.drop_duplicates(subset=['summary'])\n    logging.info(f\"Removed {initial_rows - len(df)} duplicate summaries\")\n    df = df[df['summary'].str.len() >= 5]\n    logging.info(f\"Removed {initial_rows - len(df)} summaries shorter than 5 characters\")\n    df['industry'] = df['industry'].str.strip()\n    logging.info(\"Industry labels checked and stripped\")\n    return df\n\n# Phase 3: Text Normalization\ndef normalize_text(text):\n    text = unicodedata.normalize('NFC', str(text))\n    text = ' '.join(text.split())\n    return text\n\n# Phase 4: Label Processing (with class weighting)\ndef process_labels(df):\n    # Define industry categories\n    industries = ['Finance', 'Technology', 'Healthcare', 'Energy', 'Other']\n    \n    # Map any labels not in our predefined list to 'Other'\n    df['industry'] = df['industry'].apply(lambda x: x if x in industries else 'Other')\n    \n    label2id = {industry: idx for idx, industry in enumerate(industries)}\n    id2label = {v: k for k, v in label2id.items()}\n    df['industry'] = df['industry'].map(label2id)\n    \n    distribution = df['industry'].value_counts().sort_index()\n    logging.info(f\"Class distribution: {distribution.to_dict()}\")\n    \n    if distribution.min() / distribution.max() < 0.5:\n        logging.warning(\"Significant class imbalance detected!\")\n    \n    class_weights = torch.tensor([1.0 / count for count in distribution]).to(device)\n    return df, label2id, id2label, class_weights\n\n# Phase 5: Tokenization\ndef tokenize_data(df, tokenizer):\n    df['text'] = df['summary'].apply(normalize_text)\n    df['tokenized'] = df['text'].apply(lambda x: tokenizer.encode_plus(\n        x, max_length=MAX_LEN, padding='max_length', truncation=True,\n        return_tensors='pt', add_special_tokens=True)['input_ids'].squeeze().numpy())\n    logging.info(f\"Tokenization completed with max_length={MAX_LEN}\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:53.993877Z","iopub.execute_input":"2025-07-25T03:29:53.994119Z","iopub.status.idle":"2025-07-25T03:29:54.005815Z","shell.execute_reply.started":"2025-07-25T03:29:53.994091Z","shell.execute_reply":"2025-07-25T03:29:54.004890Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"bda2bfbc-87a8-4e7b-8e71-7e6bf884f001","cell_type":"code","source":"# Dataset Class\nclass IndustryDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=MAX_LEN):\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        text = row['text']\n        label = row['industry']\n\n        encoding = self.tokenizer.encode_plus(\n            text, max_length=self.max_len, padding='max_length',\n            truncation=True, return_tensors='pt', add_special_tokens=True\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.006713Z","iopub.execute_input":"2025-07-25T03:29:54.007007Z","iopub.status.idle":"2025-07-25T03:29:54.020588Z","shell.execute_reply.started":"2025-07-25T03:29:54.006981Z","shell.execute_reply":"2025-07-25T03:29:54.019807Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"ebcf1650-88ad-4a57-abf3-f843fd7d7304","cell_type":"code","source":"# Model Definition\nclass IndustryClassifier(nn.Module):\n    def __init__(self, n_classes=5, dropout_rate=0.3):\n        super(IndustryClassifier, self).__init__()\n        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n        self.drop = nn.Dropout(p=dropout_rate)\n        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n        nn.init.normal_(self.fc.weight, std=0.02)\n        nn.init.normal_(self.fc.bias, 0)\n\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n        output = self.drop(pooled_output)\n        return self.fc(output)","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.021375Z","iopub.execute_input":"2025-07-25T03:29:54.021697Z","iopub.status.idle":"2025-07-25T03:29:54.034885Z","shell.execute_reply.started":"2025-07-25T03:29:54.021677Z","shell.execute_reply":"2025-07-25T03:29:54.034179Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"f361bbfc-3d66-4ec3-9be3-1dbb5cafdc12","cell_type":"code","source":"# Training and Evaluation Functions\ndef train_epoch(model, data_loader, criterion, optimizer, scheduler, device):\n    model.train()\n    losses = []\n    correct_predictions = 0\n\n    for batch in data_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, targets)\n        _, preds = torch.max(outputs, dim=1)\n\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n    return np.mean(losses), correct_predictions.double() / len(data_loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.035775Z","iopub.execute_input":"2025-07-25T03:29:54.036460Z","iopub.status.idle":"2025-07-25T03:29:54.049293Z","shell.execute_reply.started":"2025-07-25T03:29:54.036441Z","shell.execute_reply":"2025-07-25T03:29:54.048681Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"id":"5ae43a8e-6590-413e-b771-ce5a70771694","cell_type":"code","source":"def eval_model(model, data_loader, criterion, device):\n    model.eval()\n    losses = []\n    correct_predictions = 0\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, targets)\n            _, preds = torch.max(outputs, dim=1)\n\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n\n    return np.mean(losses), correct_predictions.double() / len(data_loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.049930Z","iopub.execute_input":"2025-07-25T03:29:54.050116Z","iopub.status.idle":"2025-07-25T03:29:54.062998Z","shell.execute_reply.started":"2025-07-25T03:29:54.050103Z","shell.execute_reply":"2025-07-25T03:29:54.062462Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"7b8b1243-9d66-4f93-9fd8-1399b9d84397","cell_type":"code","source":"def prepare_loaders(train_df, val_df, test_df, tokenizer, batch_size):\n    train_dataset = IndustryDataset(train_df, tokenizer)\n    val_dataset = IndustryDataset(val_df, tokenizer)\n    test_dataset = IndustryDataset(test_df, tokenizer)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    return train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.063760Z","iopub.execute_input":"2025-07-25T03:29:54.063982Z","iopub.status.idle":"2025-07-25T03:29:54.074642Z","shell.execute_reply.started":"2025-07-25T03:29:54.063961Z","shell.execute_reply":"2025-07-25T03:29:54.073953Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"cb352a2d-e401-4835-98e3-62f02b81e8ff","cell_type":"code","source":"# Enhanced Evaluation Function with all metrics\ndef evaluate_model(model, data_loader, id2label):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(input_ids, attention_mask)\n            probs = torch.nn.functional.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    # Use numeric labels instead of strings for metrics calculation\n    classes = list(id2label.values())\n    class_ids = list(id2label.keys())\n    \n    # ==================== PER-CLASS EVALUATION ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"DETAILED PER-CLASS EVALUATION METRICS\")\n    print(\"=\"*60)\n    \n    # Convert to string labels only for display\n    all_pred_labels = [id2label[p] for p in all_preds]\n    all_true_labels = [id2label[t] for t in all_targets]\n    \n    report = classification_report(\n        all_true_labels, \n        all_pred_labels, \n        target_names=classes,\n        digits=4,\n        output_dict=True\n    )\n    \n    class_metrics = pd.DataFrame(report).transpose().drop(['accuracy', 'macro avg', 'weighted avg'])\n    print(\"\\nPer-class metrics:\")\n    print(class_metrics.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    # ==================== OVERALL EVALUATION ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"COMPREHENSIVE OVERALL EVALUATION METRICS\")\n    print(\"=\"*60)\n    \n    # Use numeric labels (all_targets and all_preds) to calculate metrics\n    accuracy = accuracy_score(all_targets, all_preds)\n    balanced_accuracy = balanced_accuracy_score(all_targets, all_preds)\n    f1_macro = f1_score(all_targets, all_preds, average='macro')\n    f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n    kappa = cohen_kappa_score(all_targets, all_preds)\n    mcc = matthews_corrcoef(all_targets, all_preds)\n    lloss = log_loss(all_targets, all_probs, labels=class_ids)\n    h_loss = hamming_loss(all_targets, all_preds)\n    jaccard = jaccard_score(all_targets, all_preds, average='weighted')\n    \n    try:\n        top2_acc = top_k_accuracy_score(all_targets, all_probs, k=2)\n        top3_acc = top_k_accuracy_score(all_targets, all_probs, k=3)\n    except:\n        top2_acc = top3_acc = None\n    \n    # ROC AUC calculation\n    try:\n        if len(classes) == 2:\n            roc_auc = roc_auc_score(all_targets, [p[1] for p in all_probs])\n        else:\n            y_true_bin = label_binarize(all_targets, classes=class_ids)\n            roc_auc = roc_auc_score(y_true_bin, all_probs, multi_class='ovr')\n    except Exception as e:\n        print(f\"Could not calculate ROC AUC: {str(e)}\")\n        roc_auc = None\n    \n    # Precision-Recall AUC\n    try:\n        if len(classes) == 2:\n            precision, recall, _ = precision_recall_curve(all_targets, [p[1] for p in all_probs])\n            pr_auc = auc(recall, precision)\n        else:\n            pr_auc = average_precision_score(\n                label_binarize(all_targets, classes=class_ids),\n                all_probs,\n                average='macro'\n            )\n    except Exception as e:\n        print(f\"Could not calculate PR AUC: {str(e)}\")\n        pr_auc = None\n    \n    # Display overall metrics in a comprehensive table\n    overall_metrics = {\n        'Accuracy': accuracy,\n        'Balanced Accuracy': balanced_accuracy,\n        'Macro F1': f1_macro,\n        'Weighted F1': f1_weighted,\n        'Macro Precision': report['macro avg']['precision'],\n        'Macro Recall': report['macro avg']['recall'],\n        'Cohen Kappa': kappa,\n        'Matthews Corr Coef': mcc,\n        'Log Loss': lloss,\n        'Hamming Loss': h_loss,\n        'Jaccard Score': jaccard,\n    }\n    \n    if roc_auc is not None:\n        overall_metrics['ROC AUC'] = roc_auc\n    if pr_auc is not None:\n        overall_metrics['PR AUC'] = pr_auc\n    if top2_acc is not None:\n        overall_metrics['Top-2 Accuracy'] = top2_acc\n        overall_metrics['Top-3 Accuracy'] = top3_acc\n    \n    overall_df = pd.DataFrame.from_dict(overall_metrics, orient='index', columns=['Value'])\n    print(\"\\nOverall metrics:\")\n    print(overall_df.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    # ==================== VISUALIZATIONS ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION VISUALIZATIONS\")\n    print(\"=\"*60)\n    \n    # 1. Confusion matrix\n    plt.figure(figsize=(12, 10))\n    cm = confusion_matrix(all_true_labels, all_pred_labels, labels=classes)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=classes, yticklabels=classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    confusion_matrix_path = os.path.join(log_dir, 'confusion_matrix.png')\n    plt.savefig(confusion_matrix_path)\n    plt.close()\n    print(f\"\\nConfusion matrix saved to {confusion_matrix_path}\")\n    \n    # 2. Precision-Recall Curve\n    plt.figure(figsize=(12, 10))\n    if len(classes) == 2:\n        precision, recall, _ = precision_recall_curve(all_targets, [p[1] for p in all_probs])\n        plt.plot(recall, precision, lw=2, label=f'PR Curve (AUC = {pr_auc:.2f})')\n    else:\n        for i, class_name in enumerate(classes):\n            precision, recall, _ = precision_recall_curve(\n                (np.array(all_targets) == class_ids[i]).astype(int),\n                np.array(all_probs)[:, i]\n            )\n            plt.plot(recall, precision, lw=2, label=f'{class_name}')\n    \n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend(loc='best')\n    pr_curve_path = os.path.join(log_dir, 'precision_recall_curve.png')\n    plt.savefig(pr_curve_path)\n    plt.close()\n    print(f\"Precision-Recall curve saved to {pr_curve_path}\")\n    \n    # 3. ROC Curve (for binary or multiclass)\n    if roc_auc is not None:\n        plt.figure(figsize=(12, 10))\n        if len(classes) == 2:\n            fpr, tpr, _ = roc_curve(all_targets, [p[1] for p in all_probs])\n            plt.plot(fpr, tpr, lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n        else:\n            y_true_bin = label_binarize(all_targets, classes=class_ids)\n            for i, class_name in enumerate(classes):\n                fpr, tpr, _ = roc_curve(y_true_bin[:, i], np.array(all_probs)[:, i])\n                plt.plot(fpr, tpr, lw=2, label=f'{class_name}')\n        \n        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.legend(loc='best')\n        roc_curve_path = os.path.join(log_dir, 'roc_curve.png')\n        plt.savefig(roc_curve_path)\n        plt.close()\n        print(f\"ROC curve saved to {roc_curve_path}\")\n    \n    # Log all metrics\n    logging.info(\"\\n=== DETAILED PER-CLASS EVALUATION METRICS ===\")\n    logging.info(\"\\nPer-class metrics:\\n\" + class_metrics.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    logging.info(\"\\n=== COMPREHENSIVE OVERALL EVALUATION METRICS ===\")\n    logging.info(\"\\nOverall metrics:\\n\" + overall_df.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    return {\n        'class_metrics': class_metrics,\n        'overall_metrics': overall_metrics,\n        'confusion_matrix': cm,\n        'roc_auc': roc_auc,\n        'pr_auc': pr_auc,\n        'visualizations': {\n            'confusion_matrix': confusion_matrix_path,\n            'pr_curve': pr_curve_path,\n            'roc_curve': roc_curve_path if roc_auc is not None else None\n        }\n    }","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.075374Z","iopub.execute_input":"2025-07-25T03:29:54.075592Z","iopub.status.idle":"2025-07-25T03:29:54.097548Z","shell.execute_reply.started":"2025-07-25T03:29:54.075577Z","shell.execute_reply":"2025-07-25T03:29:54.096935Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"58070a13-e38d-493c-a006-39c85e749774","cell_type":"code","source":"# Train and Evaluate with Optuna\ndef train_and_evaluate(df, test_df, tokenizer, class_weights):\n    def objective(trial):\n        learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n        batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n        n_epochs = trial.suggest_int(\"n_epochs\", 5, 15)\n        \n        logging.info(f\"Trial {trial.number}: lr={learning_rate:.6f}, batch_size={batch_size}, dropout_rate={dropout_rate:.2f}, epochs={n_epochs}\")\n        \n        class IndustryClassifier(nn.Module):\n            def __init__(self, n_classes=5, dropout_rate=dropout_rate):\n                super(IndustryClassifier, self).__init__()\n                self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n                self.drop = nn.Dropout(p=dropout_rate)\n                self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n                nn.init.normal_(self.fc.weight, std=0.02)\n                nn.init.normal_(self.fc.bias, 0)\n\n            def forward(self, input_ids, attention_mask):\n                _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n                output = self.drop(pooled_output)\n                return self.fc(output)\n        \n        skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=86)\n        fold_accuracies = []\n        \n        for fold, (train_index, val_index) in enumerate(skf.split(df, df['industry'])):\n            print(f'\\nFold {fold + 1}/{N_SPLITS}')\n            train_df = df.iloc[train_index].reset_index(drop=True)\n            val_df = df.iloc[val_index].reset_index(drop=True)\n            train_loader, val_loader, _ = prepare_loaders(train_df, val_df, test_df, tokenizer, batch_size)\n            \n            model = IndustryClassifier().to(device)\n            criterion = nn.CrossEntropyLoss(weight=class_weights)\n            optimizer = AdamW(model.parameters(), lr=learning_rate)\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * n_epochs)\n            \n            best_val_acc = 0\n            patience = 3\n            epochs_no_improve = 0\n            for epoch in range(n_epochs):\n                train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n                val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n                logging.info(f\"Trial {trial.number}, Fold {fold+1}, Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n                print(f\"Epoch {epoch+1}/{n_epochs} - Val Acc: {val_acc:.4f}\")\n                \n                if val_acc > best_val_acc:\n                    best_val_acc = val_acc.cpu().item()\n                    epochs_no_improve = 0\n                else:\n                    epochs_no_improve += 1\n                    if epochs_no_improve >= patience:\n                        logging.info(f\"Early stopping triggered at epoch {epoch+1} for fold {fold+1}\")\n                        break\n            \n            fold_accuracies.append(best_val_acc)\n        \n        avg_val_acc = np.mean(fold_accuracies)\n        logging.info(f\"Trial {trial.number} completed with average validation accuracy: {avg_val_acc:.4f}\")\n        return avg_val_acc\n    \n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=3)\n    \n    best_trial = study.best_trial\n    logging.info(f\"Best trial: {best_trial.number}\")\n    logging.info(f\"Best validation accuracy: {best_trial.value:.4f}\")\n    logging.info(f\"Best hyperparameters: {best_trial.params}\")\n    \n    best_lr = best_trial.params['learning_rate']\n    best_batch_size = best_trial.params['batch_size']\n    best_dropout_rate = best_trial.params['dropout_rate']\n    best_n_epochs = best_trial.params['n_epochs']\n    \n    logging.info(f\"Training final model with best hyperparameters: lr={best_lr:.6f}, batch_size={best_batch_size}, dropout_rate={best_dropout_rate:.2f}, epochs={best_n_epochs}\")\n    \n    class IndustryClassifier(nn.Module):\n        def __init__(self, n_classes=5, dropout_rate=best_dropout_rate):\n            super(IndustryClassifier, self).__init__()\n            self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n            self.drop = nn.Dropout(p=dropout_rate)\n            self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n            nn.init.normal_(self.fc.weight, std=0.02)\n            nn.init.normal_(self.fc.bias, 0)\n\n        def forward(self, input_ids, attention_mask):\n            _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n            output = self.drop(pooled_output)\n            return self.fc(output)\n    \n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=86)\n    best_accuracy = 0\n    best_model_path = None\n    \n    for fold, (train_index, val_index) in enumerate(skf.split(df, df['industry'])):\n        print(f'\\nFinal Training - Fold {fold + 1}/{N_SPLITS}')\n        train_df = df.iloc[train_index].reset_index(drop=True)\n        val_df = df.iloc[val_index].reset_index(drop=True)\n        train_loader, val_loader, _ = prepare_loaders(train_df, val_df, test_df, tokenizer, best_batch_size)\n        \n        model = IndustryClassifier().to(device)\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n        optimizer = AdamW(model.parameters(), lr=best_lr)\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * best_n_epochs)\n        \n        best_val_acc = 0\n        patience = 3\n        epochs_no_improve = 0\n        for epoch in range(best_n_epochs):\n            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n            val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n            logging.info(f\"Final Training, Fold {fold+1}, Epoch {epoch+1}/{best_n_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n            print(f\"Epoch {epoch+1}/{best_n_epochs} - Val Acc: {val_acc:.4f}\")\n            \n            if val_acc > best_val_acc:\n                best_val_acc = val_acc.cpu().item()\n                epochs_no_improve = 0\n                if best_val_acc > best_accuracy:\n                    best_accuracy = best_val_acc\n                    best_model_path = os.path.join(log_dir, f'PhoBERT_industry_temp.bin')\n                    torch.save(model.state_dict(), best_model_path)\n                    logging.info(f\"Saved best model at fold {fold+1}, epoch {epoch+1} with accuracy {val_acc:.4f}\")\n            else:\n                epochs_no_improve += 1\n                if epochs_no_improve >= patience:\n                    logging.info(f\"Early stopping triggered at epoch {epoch+1} for fold {fold+1}\")\n                    break\n    \n    model.load_state_dict(torch.load(best_model_path))\n    os.remove(best_model_path)\n    final_model_path = os.path.join(log_dir, 'PhoBERT_industry_classification.bin')\n    torch.save(model.state_dict(), final_model_path)\n    logging.info(f\"Final best model saved as PhoBERT_industry_classification.bin with accuracy {best_accuracy:.4f}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.098285Z","iopub.execute_input":"2025-07-25T03:29:54.098530Z","iopub.status.idle":"2025-07-25T03:29:54.118075Z","shell.execute_reply.started":"2025-07-25T03:29:54.098509Z","shell.execute_reply":"2025-07-25T03:29:54.117364Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"1d4ba011-c429-4346-b8b5-17719126f4b7","cell_type":"code","source":"# Inference Function\ndef predict_industry(text, model, tokenizer, id2label):\n    dataset = IndustryDataset(pd.DataFrame({'text': [text], 'industry': [0]}), tokenizer)\n    data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n\n    model.eval()\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            _, pred = torch.max(outputs, dim=1)\n    return id2label[pred.item()]","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.118835Z","iopub.execute_input":"2025-07-25T03:29:54.119054Z","iopub.status.idle":"2025-07-25T03:29:54.132739Z","shell.execute_reply.started":"2025-07-25T03:29:54.119032Z","shell.execute_reply":"2025-07-25T03:29:54.132184Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"8824baca-587d-478a-984a-1393cb0ac51d","cell_type":"code","source":"# Zip output files for download\ndef zip_and_download_output_files():\n    output_zip = os.path.join(log_dir, 'output_files.zip')\n    output_files = [\n        'training_industry_classification_log.txt',\n        'data_processed_for_industry_classification.csv',\n        'PhoBERT_industry_classification.bin',\n        'confusion_matrix.png',\n        'precision_recall_curve.png',\n        'roc_curve.png'\n    ]\n    \n    # Only include existing files\n    existing_files = [f for f in output_files if os.path.exists(os.path.join(log_dir, f))]\n    missing_files = set(output_files) - set(existing_files)\n    \n    if missing_files:\n        logging.warning(f\"Missing files: {missing_files}\")\n    \n    try:\n        with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for file in existing_files:\n                file_path = os.path.join(log_dir, file)\n                zipf.write(file_path, file)\n                logging.info(f\"Added {file} to zip archive\")\n        \n        if os.path.exists(output_zip):\n            logging.info(f\"Zip file created at {output_zip}\")\n            \n            # Automatic download\n            print(\"\\n\" + \"=\"*60)\n            print(\"AUTOMATICALLY DOWNLOADING OUTPUT FILES\")\n            print(\"=\"*60)\n            \n            # For Kaggle\n            if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n                print(\"In Kaggle environment, please download manually:\")\n                display(FileLink('output_files.zip'))\n            # For Google Colab\n            else:\n                print(\"Downloading output files automatically...\")\n                from google.colab import files\n                files.download(output_zip)\n            \n            return output_zip\n        else:\n            logging.error(\"Failed to create zip file\")\n            return None\n    except Exception as e:\n        logging.error(f\"Error creating zip: {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.133444Z","iopub.execute_input":"2025-07-25T03:29:54.133713Z","iopub.status.idle":"2025-07-25T03:29:54.145745Z","shell.execute_reply.started":"2025-07-25T03:29:54.133697Z","shell.execute_reply":"2025-07-25T03:29:54.145008Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"844164b5-030b-4a16-ae99-ecde8d4f66bd","cell_type":"code","source":"# Main Execution\nif __name__ == \"__main__\":\n    try:\n        xlsx_path = '/kaggle/input/data-industry-v4-fix/data_industry_v4_fix.xlsx'\n        if not os.path.exists(xlsx_path):\n            raise FileNotFoundError(f\"File {xlsx_path} not found!\")\n        print(f\"Found data file at {xlsx_path}\")\n        print(\"Loading data...\")\n        df_processed = load_original_data(xlsx_path)\n        print(\"Cleaning data...\")\n        df_processed = clean_data(df_processed)\n        print(\"Processing labels...\")\n        df_processed, label2id, id2label, class_weights = process_labels(df_processed)\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n        print(\"Tokenizer loaded successfully.\")\n        print(\"Tokenizing data...\")\n        df_processed = tokenize_data(df_processed, tokenizer)\n\n        processed_data_path = os.path.join(log_dir, 'data_processed_for_industry_classification.csv')\n        df_processed.to_csv(processed_data_path, index=False)\n        logging.info(f\"Saved processed data with shape: {df_processed.shape}\")\n\n        summary_lengths = df_processed['text'].str.len()\n        token_lengths = [len(t) for t in df_processed['tokenized']]\n        logging.info(f\"Summary length stats: Min={summary_lengths.min()}, Max={summary_lengths.max()}, Mean={summary_lengths.mean():.2f}\")\n        logging.info(f\"Token length stats: Min={min(token_lengths)}, Max={max(token_lengths)}, Mean={np.mean(token_lengths):.2f}\")\n        logging.info(f\"Processing config: max_len={MAX_LEN}, n_splits={N_SPLITS}\")\n\n        train_val_df, test_df = train_test_split(df_processed, test_size=0.2, stratify=df_processed['industry'], random_state=86)\n        logging.info(f\"Data split: Train+Val={len(train_val_df)}, Test={len(test_df)}\")\n\n        print(\"Starting training with Optuna optimization...\")\n        model = train_and_evaluate(train_val_df, test_df, tokenizer, class_weights)\n\n        print(\"Evaluating model...\")\n        _, _, test_loader = prepare_loaders(train_val_df, train_val_df, test_df, tokenizer, batch_size=16)\n        evaluation_results = evaluate_model(model, test_loader, id2label)\n\n        sample_text = \"Ngân hàng Techcombank công bố lợi nhuận quý 3 tăng trưởng 25% nhờ tăng trưởng tín dụng và thu nhập từ dịch vụ ngân hàng\"\n        predicted_industry = predict_industry(sample_text, model, tokenizer, id2label)\n        print(f\"\\nSample text: {sample_text}\")\n        print(f\"Predicted industry: {predicted_industry}\")\n        logging.info(f\"Inference test: Text='{sample_text}', Predicted='{predicted_industry}'\")\n\n        print(\"\\nPreparing output files for download...\")\n        zip_and_download_output_files()\n\n    except Exception as e:\n        logging.error(f\"Error in main execution: {e}\", exc_info=True)\n        raise","metadata":{"execution":{"iopub.status.busy":"2025-07-25T03:29:54.146545Z","iopub.execute_input":"2025-07-25T03:29:54.147312Z","iopub.status.idle":"2025-07-25T10:07:02.313883Z","shell.execute_reply.started":"2025-07-25T03:29:54.147284Z","shell.execute_reply":"2025-07-25T10:07:02.313187Z"},"papermill":{"duration":29496.954321,"end_time":"2025-07-22T00:52:52.782162","exception":false,"start_time":"2025-07-21T16:41:15.827841","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Found data file at /kaggle/input/data-industry-v4-fix/data_industry_v4_fix.xlsx\nLoading data...\n","output_type":"stream"},{"name":"stderr","text":"2025-07-25 03:29:56,238 - WARNING - Significant class imbalance detected!\n","output_type":"stream"},{"name":"stdout","text":"Cleaning data...\nProcessing labels...\nLoading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b964aff9fbff45bfa021a7075bdfba3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be55514eb6741a1ac573f71d548bb19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bdb24c399d34dac974ab676f5c8039f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ca9511745e4e0c84cc0cc830e27af6"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded successfully.\nTokenizing data...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-25 03:30:15,208] A new study created in memory with name: no-name-baad6499-89fc-4b57-90e8-104f877a2357\n","output_type":"stream"},{"name":"stdout","text":"Starting training with Optuna optimization...\n\nFold 1/3\n","output_type":"stream"},{"name":"stderr","text":"2025-07-25 03:30:26.040250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753414226.236942      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753414226.293437      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1162499103544edbf50810a553a8082"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1666c665c0e54f0a91e35ac40d89f5db"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Val Acc: 0.8029\nEpoch 2/5 - Val Acc: 0.8205\nEpoch 3/5 - Val Acc: 0.8236\nEpoch 4/5 - Val Acc: 0.8202\nEpoch 5/5 - Val Acc: 0.8177\n\nFold 2/3\nEpoch 1/5 - Val Acc: 0.7916\nEpoch 2/5 - Val Acc: 0.8130\nEpoch 3/5 - Val Acc: 0.8098\nEpoch 4/5 - Val Acc: 0.8086\nEpoch 5/5 - Val Acc: 0.8101\n\nFold 3/3\nEpoch 1/5 - Val Acc: 0.8252\nEpoch 2/5 - Val Acc: 0.8035\nEpoch 3/5 - Val Acc: 0.8355\nEpoch 4/5 - Val Acc: 0.8352\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-25 04:54:06,847] Trial 0 finished with value: 0.8240422859259345 and parameters: {'learning_rate': 1.4048563467972254e-05, 'batch_size': 16, 'dropout_rate': 0.2999296793773678, 'n_epochs': 5}. Best is trial 0 with value: 0.8240422859259345.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Val Acc: 0.8343\n\nFold 1/3\nEpoch 1/12 - Val Acc: 0.7960\nEpoch 2/12 - Val Acc: 0.7960\nEpoch 3/12 - Val Acc: 0.8152\nEpoch 4/12 - Val Acc: 0.8158\nEpoch 5/12 - Val Acc: 0.8155\nEpoch 6/12 - Val Acc: 0.8180\nEpoch 7/12 - Val Acc: 0.8152\nEpoch 8/12 - Val Acc: 0.8082\nEpoch 9/12 - Val Acc: 0.8079\n\nFold 2/3\nEpoch 1/12 - Val Acc: 0.7938\nEpoch 2/12 - Val Acc: 0.8089\nEpoch 3/12 - Val Acc: 0.8073\nEpoch 4/12 - Val Acc: 0.8114\nEpoch 5/12 - Val Acc: 0.7887\nEpoch 6/12 - Val Acc: 0.8101\nEpoch 7/12 - Val Acc: 0.8089\n\nFold 3/3\nEpoch 1/12 - Val Acc: 0.8154\nEpoch 2/12 - Val Acc: 0.8242\nEpoch 3/12 - Val Acc: 0.8170\nEpoch 4/12 - Val Acc: 0.8286\nEpoch 5/12 - Val Acc: 0.8230\nEpoch 6/12 - Val Acc: 0.8292\nEpoch 7/12 - Val Acc: 0.8145\nEpoch 8/12 - Val Acc: 0.8308\nEpoch 9/12 - Val Acc: 0.8239\nEpoch 10/12 - Val Acc: 0.8289\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-25 07:24:10,713] Trial 1 finished with value: 0.8200598153211844 and parameters: {'learning_rate': 1.033040866861796e-05, 'batch_size': 16, 'dropout_rate': 0.40027595946657435, 'n_epochs': 12}. Best is trial 0 with value: 0.8240422859259345.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/12 - Val Acc: 0.8264\n\nFold 1/3\nEpoch 1/5 - Val Acc: 0.8101\nEpoch 2/5 - Val Acc: 0.7969\nEpoch 3/5 - Val Acc: 0.8048\nEpoch 4/5 - Val Acc: 0.8041\n\nFold 2/3\nEpoch 1/5 - Val Acc: 0.8070\nEpoch 2/5 - Val Acc: 0.8079\nEpoch 3/5 - Val Acc: 0.8158\nEpoch 4/5 - Val Acc: 0.8145\nEpoch 5/5 - Val Acc: 0.8177\n\nFold 3/3\nEpoch 1/5 - Val Acc: 0.8296\nEpoch 2/5 - Val Acc: 0.8314\nEpoch 3/5 - Val Acc: 0.8270\nEpoch 4/5 - Val Acc: 0.8252\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-25 08:42:06,328] Trial 2 finished with value: 0.8197455146747229 and parameters: {'learning_rate': 4.2218557024191564e-05, 'batch_size': 16, 'dropout_rate': 0.4988719107323133, 'n_epochs': 5}. Best is trial 0 with value: 0.8240422859259345.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Val Acc: 0.8305\n\nFinal Training - Fold 1/3\nEpoch 1/5 - Val Acc: 0.7997\nEpoch 2/5 - Val Acc: 0.8265\nEpoch 3/5 - Val Acc: 0.8192\nEpoch 4/5 - Val Acc: 0.8218\nEpoch 5/5 - Val Acc: 0.8218\n\nFinal Training - Fold 2/3\nEpoch 1/5 - Val Acc: 0.7935\nEpoch 2/5 - Val Acc: 0.8073\nEpoch 3/5 - Val Acc: 0.8148\nEpoch 4/5 - Val Acc: 0.8064\nEpoch 5/5 - Val Acc: 0.8082\n\nFinal Training - Fold 3/3\nEpoch 1/5 - Val Acc: 0.7802\nEpoch 2/5 - Val Acc: 0.8255\nEpoch 3/5 - Val Acc: 0.8318\nEpoch 4/5 - Val Acc: 0.8374\nEpoch 5/5 - Val Acc: 0.8349\nEvaluating model...\n\n============================================================\nDETAILED PER-CLASS EVALUATION METRICS\n============================================================\n\nPer-class metrics:\n+------------+-------------+----------+------------+-----------+\n|            |   precision |   recall |   f1-score |   support |\n+============+=============+==========+============+===========+\n| Finance    |      0.8702 |   0.9459 |     0.9065 |  333.0000 |\n+------------+-------------+----------+------------+-----------+\n| Technology |      0.9128 |   0.7782 |     0.8401 |  888.0000 |\n+------------+-------------+----------+------------+-----------+\n| Healthcare |      0.8198 |   0.9338 |     0.8731 |  151.0000 |\n+------------+-------------+----------+------------+-----------+\n| Energy     |      0.7572 |   0.8091 |     0.7823 |  744.0000 |\n+------------+-------------+----------+------------+-----------+\n| Other      |      0.7767 |   0.8630 |     0.8175 |  270.0000 |\n+------------+-------------+----------+------------+-----------+\n\n============================================================\nCOMPREHENSIVE OVERALL EVALUATION METRICS\n============================================================\n\nOverall metrics:\n+--------------------+---------+\n|                    |   Value |\n+====================+=========+\n| Accuracy           |  0.8307 |\n+--------------------+---------+\n| Balanced Accuracy  |  0.8660 |\n+--------------------+---------+\n| Macro F1           |  0.8439 |\n+--------------------+---------+\n| Weighted F1        |  0.8309 |\n+--------------------+---------+\n| Macro Precision    |  0.8273 |\n+--------------------+---------+\n| Macro Recall       |  0.8660 |\n+--------------------+---------+\n| Cohen Kappa        |  0.7706 |\n+--------------------+---------+\n| Matthews Corr Coef |  0.7727 |\n+--------------------+---------+\n| Log Loss           |  0.5044 |\n+--------------------+---------+\n| Hamming Loss       |  0.1693 |\n+--------------------+---------+\n| Jaccard Score      |  0.7129 |\n+--------------------+---------+\n| ROC AUC            |  0.9668 |\n+--------------------+---------+\n| PR AUC             |  0.9067 |\n+--------------------+---------+\n| Top-2 Accuracy     |  0.9673 |\n+--------------------+---------+\n| Top-3 Accuracy     |  0.9937 |\n+--------------------+---------+\n\n============================================================\nEVALUATION VISUALIZATIONS\n============================================================\n\nConfusion matrix saved to /kaggle/working/confusion_matrix.png\nPrecision-Recall curve saved to /kaggle/working/precision_recall_curve.png\nROC curve saved to /kaggle/working/roc_curve.png\n\nSample text: Ngân hàng Techcombank công bố lợi nhuận quý 3 tăng trưởng 25% nhờ tăng trưởng tín dụng và thu nhập từ dịch vụ ngân hàng\nPredicted industry: Finance\n\nPreparing output files for download...\n\n============================================================\nAUTOMATICALLY DOWNLOADING OUTPUT FILES\n============================================================\nIn Kaggle environment, please download manually:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output_files.zip","text/html":"<a href='output_files.zip' target='_blank'>output_files.zip</a><br>"},"metadata":{}}],"execution_count":18},{"id":"84d2856b","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.030312,"end_time":"2025-07-22T00:52:52.843412","exception":false,"start_time":"2025-07-22T00:52:52.813100","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}