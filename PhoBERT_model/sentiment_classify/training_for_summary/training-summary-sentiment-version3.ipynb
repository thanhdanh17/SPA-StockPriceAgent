{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12531572,"sourceType":"datasetVersion","datasetId":7910800}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":5772.497852,"end_time":"2025-07-01T23:25:43.586847","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-01T21:49:31.088995","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"070603df2ce84f0fac225a82210a4809":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07c2d69ff4584faba1c3bdce5203d5e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09243ea0b73f42c6bece648697030dcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_95e23848fd9a45a8ba4cec8a0fd2670b","placeholder":"​","style":"IPY_MODEL_54658c615a5e43e391dfc3d7ad6bb24f","tabbable":null,"tooltip":null,"value":"bpe.codes: "}},"0d624dd3c4ea45799f93d56c6d50e8a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"105955edd1424950b13c2955ae2a87ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_edc44a0a86684ac59970bcf2a2bd9ba9","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5367699072214c8aa938bf0cbbd1788c","tabbable":null,"tooltip":null,"value":542923308}},"11ff40ed8ca8480990065b8f86aa3e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"12a728f68c3c4281ba3f60c3e7dabac5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1c9baba668624dea8e1ca5dcba4e5368","placeholder":"​","style":"IPY_MODEL_e79df1158f6a4e09805bf0b67455eede","tabbable":null,"tooltip":null,"value":" 3.13M/? [00:00&lt;00:00, 25.6MB/s]"}},"14c07404656c45c995bd57519b259769":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18eb0c21e2e349ea82c39762a8d1925c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_34f646b94e9a410987364aa6b9c0954d","placeholder":"​","style":"IPY_MODEL_0d624dd3c4ea45799f93d56c6d50e8a0","tabbable":null,"tooltip":null,"value":" 557/557 [00:00&lt;00:00, 56.3kB/s]"}},"1a90b953094f408c9f7b8f77f5b26cdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c9baba668624dea8e1ca5dcba4e5368":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abdf0a07f2c4a858e70f50155d64d74":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2d50448ab40044e88137fb41cefb827f","placeholder":"​","style":"IPY_MODEL_68dffd270be24616a1cf5bd065569bff","tabbable":null,"tooltip":null,"value":"vocab.txt: "}},"2d50448ab40044e88137fb41cefb827f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d6485c846ad4ba88901dc111cb0eef1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34f646b94e9a410987364aa6b9c0954d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36293d007bd8433db0ac9e4c423895ca":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37683f7afb6d465ca89c63314f8571fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f995526872ae4d60b4dd435294405808","placeholder":"​","style":"IPY_MODEL_c7a5ececc88a418b8753e4e1cb8f4093","tabbable":null,"tooltip":null,"value":" 543M/543M [00:15&lt;00:00, 36.8MB/s]"}},"3790e0c9a8574f779681e6cc9fc6cc23":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_14c07404656c45c995bd57519b259769","placeholder":"​","style":"IPY_MODEL_f29b56950096420bb82d3544a95c228a","tabbable":null,"tooltip":null,"value":"pytorch_model.bin: 100%"}},"39734b70ef8645d88d2936a3a4186e49":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f16bc12c97b499d8b77260d2ce51eb3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5367699072214c8aa938bf0cbbd1788c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53ff0b35783e48f797ede2a019fe5bfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5591fa6a7f964f7bb488d33993b46b84","IPY_MODEL_e16675f5a57641d691f0802bc0d522a2","IPY_MODEL_18eb0c21e2e349ea82c39762a8d1925c"],"layout":"IPY_MODEL_976526d852b347d7a41ecb81afb4e495","tabbable":null,"tooltip":null}},"54658c615a5e43e391dfc3d7ad6bb24f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5591fa6a7f964f7bb488d33993b46b84":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_dd9ca0018d0f48adb64f90fe6f97381a","placeholder":"​","style":"IPY_MODEL_8db9492811a94825ae529b690643720f","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"5abb4a1ec9844abe81e5a308d343018a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a9418f0a6f3a4b10a77d222378e9ec37","placeholder":"​","style":"IPY_MODEL_d9475b068a8646f48bb9c119b39d5c0b","tabbable":null,"tooltip":null,"value":"tokenizer.json: "}},"6764a9abeac34118a133a3e80501fba8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2abdf0a07f2c4a858e70f50155d64d74","IPY_MODEL_f18a8e5f4c6d47cbb2ddb0df04cff19b","IPY_MODEL_77c0925267744c83a598895414119095"],"layout":"IPY_MODEL_b8b24d816df342058968ae877a9c2016","tabbable":null,"tooltip":null}},"68dffd270be24616a1cf5bd065569bff":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6c055231274942ce8dc23b386e12c492":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77c0925267744c83a598895414119095":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_36293d007bd8433db0ac9e4c423895ca","placeholder":"​","style":"IPY_MODEL_94952ead9b3143b88ed2d2d8f9bd2677","tabbable":null,"tooltip":null,"value":" 895k/? [00:00&lt;00:00, 2.09MB/s]"}},"78bc7de82ebd493695af6f91e44b5f57":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87d1ababa74f4c7da4f56a51203f9788":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8feedb4db4cb447480121b6eb3d761e1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a90b953094f408c9f7b8f77f5b26cdd","tabbable":null,"tooltip":null,"value":1}},"8a9ce194801e4773a9adf279b0876b39":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8db9492811a94825ae529b690643720f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8ded8698e32144a48e77b499daa6a683":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8f23f9974d084f55860666fd67124dc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8feedb4db4cb447480121b6eb3d761e1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"94952ead9b3143b88ed2d2d8f9bd2677":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"95e23848fd9a45a8ba4cec8a0fd2670b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"976526d852b347d7a41ecb81afb4e495":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc62ebb620147f28839660b26df3d47":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_c659c87610bf4520ba94aa5143c65528","max":542900336,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78bc7de82ebd493695af6f91e44b5f57","tabbable":null,"tooltip":null,"value":542900336}},"a0430599f8744c6ea110c5ea0a9f93da":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3f16bc12c97b499d8b77260d2ce51eb3","placeholder":"​","style":"IPY_MODEL_11ff40ed8ca8480990065b8f86aa3e67","tabbable":null,"tooltip":null,"value":" 543M/543M [00:16&lt;00:00, 35.1MB/s]"}},"a9418f0a6f3a4b10a77d222378e9ec37":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b89cb576d86c416f9dfae18935b7a626":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b8b24d816df342058968ae877a9c2016":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbedcb14c76849e2b4bb842983b5ef83":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5abb4a1ec9844abe81e5a308d343018a","IPY_MODEL_87d1ababa74f4c7da4f56a51203f9788","IPY_MODEL_12a728f68c3c4281ba3f60c3e7dabac5"],"layout":"IPY_MODEL_39734b70ef8645d88d2936a3a4186e49","tabbable":null,"tooltip":null}},"c659c87610bf4520ba94aa5143c65528":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a0516b5eb047288a98758333419d9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e38e6416dc244709b66d01edfd5b9b02","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c055231274942ce8dc23b386e12c492","tabbable":null,"tooltip":null,"value":1}},"c7a5ececc88a418b8753e4e1cb8f4093":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c9a3e880335b4d9a9b57805709207c1b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d18683560f5f4c1891f938f6b923f58a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5e346a66de440f2a295046fe44e4cdc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9475b068a8646f48bb9c119b39d5c0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"dd9ca0018d0f48adb64f90fe6f97381a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de10e1015d1f41ef8cf9b6007f1ca82e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d18683560f5f4c1891f938f6b923f58a","placeholder":"​","style":"IPY_MODEL_8ded8698e32144a48e77b499daa6a683","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"e16675f5a57641d691f0802bc0d522a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9a3e880335b4d9a9b57805709207c1b","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f23f9974d084f55860666fd67124dc0","tabbable":null,"tooltip":null,"value":557}},"e29cd63096894d9da94d72f1e24861c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09243ea0b73f42c6bece648697030dcf","IPY_MODEL_c6a0516b5eb047288a98758333419d9a","IPY_MODEL_fe9cc692372a4fa1b55d85a94752c56d"],"layout":"IPY_MODEL_d5e346a66de440f2a295046fe44e4cdc","tabbable":null,"tooltip":null}},"e38e6416dc244709b66d01edfd5b9b02":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e79df1158f6a4e09805bf0b67455eede":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e9e84009651d4c999156e2f445105913":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3790e0c9a8574f779681e6cc9fc6cc23","IPY_MODEL_105955edd1424950b13c2955ae2a87ce","IPY_MODEL_37683f7afb6d465ca89c63314f8571fe"],"layout":"IPY_MODEL_070603df2ce84f0fac225a82210a4809","tabbable":null,"tooltip":null}},"edc44a0a86684ac59970bcf2a2bd9ba9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18a8e5f4c6d47cbb2ddb0df04cff19b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b89cb576d86c416f9dfae18935b7a626","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07c2d69ff4584faba1c3bdce5203d5e3","tabbable":null,"tooltip":null,"value":1}},"f29b56950096420bb82d3544a95c228a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f90baa03b9934af49eda763ce436f5ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de10e1015d1f41ef8cf9b6007f1ca82e","IPY_MODEL_9bc62ebb620147f28839660b26df3d47","IPY_MODEL_a0430599f8744c6ea110c5ea0a9f93da"],"layout":"IPY_MODEL_2d6485c846ad4ba88901dc111cb0eef1","tabbable":null,"tooltip":null}},"f995526872ae4d60b4dd435294405808":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe68641470f246f19d3cd2d4111114af":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe9cc692372a4fa1b55d85a94752c56d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_fe68641470f246f19d3cd2d4111114af","placeholder":"​","style":"IPY_MODEL_8a9ce194801e4773a9adf279b0876b39","tabbable":null,"tooltip":null,"value":" 1.14M/? [00:00&lt;00:00, 8.03MB/s]"}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a7fcff87","cell_type":"code","source":"# Install required packages\n!pip install transformers\n!pip install pyvi\n!pip install pandas\n!pip install seaborn\n!pip install matplotlib\n!pip install scikit-learn\n!pip install torch\n!pip install openpyxl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":98.771774,"end_time":"2025-07-01T21:51:14.166304","exception":false,"start_time":"2025-07-01T21:49:35.394530","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T19:59:34.695914Z","iopub.execute_input":"2025-07-28T19:59:34.696123Z","iopub.status.idle":"2025-07-28T20:01:26.864323Z","shell.execute_reply.started":"2025-07-28T19:59:34.696104Z","shell.execute_reply":"2025-07-28T20:01:26.863286Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nCollecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pyvi) (3.6.0)\nCollecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite->pyvi) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->pyvi) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->pyvi) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->pyvi) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->pyvi) (2024.2.0)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\nDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.11 pyvi-0.1.1 sklearn-crfsuite-0.5.0\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\nRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","output_type":"stream"}],"execution_count":1},{"id":"a0d311cb","cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pyvi import ViTokenizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import (\n    classification_report, \n    confusion_matrix, \n    accuracy_score, \n    balanced_accuracy_score,\n    f1_score,\n    roc_auc_score,\n    roc_curve, \n    precision_recall_curve,\n    auc,\n    average_precision_score,\n    cohen_kappa_score,\n    matthews_corrcoef,\n    log_loss,\n    hamming_loss,\n    jaccard_score,\n    top_k_accuracy_score\n)\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.utils import resample\nimport logging\nfrom datetime import datetime\nimport unicodedata\nimport zipfile\nfrom IPython.display import FileLink, display\n\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\nimport optuna","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":15.445388,"end_time":"2025-07-01T21:51:29.636722","exception":false,"start_time":"2025-07-01T21:51:14.191334","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:26.865426Z","iopub.execute_input":"2025-07-28T20:01:26.865708Z","iopub.status.idle":"2025-07-28T20:01:42.936084Z","shell.execute_reply.started":"2025-07-28T20:01:26.865677Z","shell.execute_reply":"2025-07-28T20:01:42.935510Z"}},"outputs":[],"execution_count":2},{"id":"8048b037","cell_type":"code","source":"# Set up logging\nlog_dir = '/kaggle/working/'\nos.makedirs(log_dir, exist_ok=True)\nlog_file = os.path.join(log_dir, 'training_summary_sentiment_log_edit_1807.txt')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.030474,"end_time":"2025-07-01T21:51:29.691901","exception":false,"start_time":"2025-07-01T21:51:29.661427","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:42.937741Z","iopub.execute_input":"2025-07-28T20:01:42.938085Z","iopub.status.idle":"2025-07-28T20:01:42.942259Z","shell.execute_reply.started":"2025-07-28T20:01:42.938067Z","shell.execute_reply":"2025-07-28T20:01:42.941564Z"}},"outputs":[],"execution_count":3},{"id":"d8f6ddc9","cell_type":"code","source":"# Remove existing log file if it exists\nif os.path.exists(log_file):\n    try:\n        os.remove(log_file)\n    except Exception as e:\n        print(f\"Could not remove existing log file: {e}\")\n\n# Configure logging\ntry:\n    logging.getLogger().handlers.clear()\n    file_handler = logging.FileHandler(log_file)\n    file_handler.setLevel(logging.INFO)\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.WARNING)\n    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n    logging.basicConfig(\n        level=logging.INFO,\n        handlers=[file_handler, console_handler],\n        force=True\n    )\n    logging.info(\"Logging initialized successfully\")\n    print(f\"Log file will be saved to: {log_file}\")\nexcept Exception as e:\n    print(f\"Failed to initialize logging to file: {e}. Using console logging only.\")\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[console_handler]\n    )","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.033818,"end_time":"2025-07-01T21:51:29.751694","exception":false,"start_time":"2025-07-01T21:51:29.717876","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:42.942972Z","iopub.execute_input":"2025-07-28T20:01:42.943182Z","iopub.status.idle":"2025-07-28T20:01:42.964608Z","shell.execute_reply.started":"2025-07-28T20:01:42.943167Z","shell.execute_reply":"2025-07-28T20:01:42.963933Z"}},"outputs":[{"name":"stdout","text":"Log file will be saved to: /kaggle/working/training_summary_sentiment_log_edit_1807.txt\n","output_type":"stream"}],"execution_count":4},{"id":"5a45702f","cell_type":"code","source":"# Seed everything for reproducibility\ndef seed_everything(seed_value):\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed_everything(86)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Configuration\nMAX_LEN = 256 \nN_SPLITS = 3","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.034556,"end_time":"2025-07-01T21:51:29.809929","exception":false,"start_time":"2025-07-01T21:51:29.775373","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:42.965268Z","iopub.execute_input":"2025-07-28T20:01:42.965551Z","iopub.status.idle":"2025-07-28T20:01:43.082858Z","shell.execute_reply.started":"2025-07-28T20:01:42.965523Z","shell.execute_reply":"2025-07-28T20:01:43.082147Z"}},"outputs":[],"execution_count":5},{"id":"b8416874","cell_type":"code","source":"# Phase 1: Load Data\ndef load_original_data(xlsx_path):\n    original_df = pd.read_excel(xlsx_path)\n    df_processed = original_df[['summary', 'sentiment']].copy()\n    logging.info(f\"Original data loaded with shape: {original_df.shape}\")\n    assert original_df.equals(pd.read_excel(xlsx_path)), \"Original data modified!\"\n    return df_processed\n\n# Phase 2: Data Cleaning\ndef clean_data(df):\n    nan_rows = df[df['summary'].isna() | df['sentiment'].isna()]\n    if not nan_rows.empty:\n        df = df.dropna(subset=['summary', 'sentiment'])\n        logging.info(f\"Removed {len(nan_rows)} rows with NaN values\")\n    initial_rows = len(df)\n    df = df.drop_duplicates(subset=['summary'])\n    logging.info(f\"Removed {initial_rows - len(df)} duplicate summaries\")\n    df = df[df['summary'].str.len() >= 5]\n    logging.info(f\"Removed {initial_rows - len(df)} summaries shorter than 5 characters\")\n    valid_labels = {'Positive', 'Negative', 'Neutral'}\n    invalid_labels = set(df['sentiment']) - valid_labels\n    if invalid_labels:\n        raise ValueError(f\"Invalid sentiment labels found: {invalid_labels}\")\n    df['sentiment'] = df['sentiment'].str.strip()\n    logging.info(\"Sentiment labels checked and stripped\")\n    return df\n\n# Phase 3: Text Normalization\ndef normalize_text(text):\n    text = unicodedata.normalize('NFC', str(text))\n    text = ' '.join(text.split())\n    return text\n\n# Phase 4: Label Processing (with class weighting)\ndef process_labels(df):\n    label2id = {'Positive': 0, 'Negative': 1, 'Neutral': 2}\n    id2label = {v: k for k, v in label2id.items()}\n    df['sentiment'] = df['sentiment'].map(label2id)\n    distribution = df['sentiment'].value_counts().sort_index()\n    logging.info(f\"Class distribution: {distribution.to_dict()}\")\n    if distribution.min() / distribution.max() < 0.5:\n        logging.warning(\"Significant class imbalance detected!\")\n    class_weights = torch.tensor([1.0 / count for count in distribution]).to(device)\n    return df, label2id, id2label, class_weights\n\n# Phase 5: Tokenization\ndef tokenize_data(df, tokenizer):\n    df['text'] = df['summary'].apply(normalize_text)\n    df['tokenized'] = df['text'].apply(lambda x: tokenizer.encode_plus(\n        x, max_length=MAX_LEN, padding='max_length', truncation=True,\n        return_tensors='pt', add_special_tokens=True)['input_ids'].squeeze().numpy())\n    logging.info(f\"Tokenization completed with max_length={MAX_LEN}\")\n    return df\n# Dataset Class\nclass SentimentDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=MAX_LEN):\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        text = row['text']\n        label = row['sentiment']\n\n        encoding = self.tokenizer.encode_plus(\n            text, max_length=self.max_len, padding='max_length',\n            truncation=True, return_tensors='pt', add_special_tokens=True\n        )\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'targets': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.03685,"end_time":"2025-07-01T21:51:29.870172","exception":false,"start_time":"2025-07-01T21:51:29.833322","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.083670Z","iopub.execute_input":"2025-07-28T20:01:43.083942Z","iopub.status.idle":"2025-07-28T20:01:43.095292Z","shell.execute_reply.started":"2025-07-28T20:01:43.083913Z","shell.execute_reply":"2025-07-28T20:01:43.094692Z"}},"outputs":[],"execution_count":6},{"id":"07155db2","cell_type":"code","source":"# Model Definition\nclass SentimentClassifier(nn.Module):\n    def __init__(self, n_classes=3, dropout_rate=0.3):\n        super(SentimentClassifier, self).__init__()\n        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n        self.drop = nn.Dropout(p=dropout_rate)\n        self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n        nn.init.normal_(self.fc.weight, std=0.02)\n        nn.init.normal_(self.fc.bias, 0)\n\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n        output = self.drop(pooled_output)\n        return self.fc(output)\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.074441,"end_time":"2025-07-01T21:51:29.968076","exception":false,"start_time":"2025-07-01T21:51:29.893635","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.096070Z","iopub.execute_input":"2025-07-28T20:01:43.096315Z","iopub.status.idle":"2025-07-28T20:01:43.117323Z","shell.execute_reply.started":"2025-07-28T20:01:43.096291Z","shell.execute_reply":"2025-07-28T20:01:43.116446Z"}},"outputs":[],"execution_count":7},{"id":"7f9640b1","cell_type":"code","source":"# Training and Evaluation Functions\ndef train_epoch(model, data_loader, criterion, optimizer, scheduler, device):\n    model.train()\n    losses = []\n    correct_predictions = 0\n\n    for batch in data_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['targets'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, targets)\n        _, preds = torch.max(outputs, dim=1)\n\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n\n    return np.mean(losses), correct_predictions.double() / len(data_loader.dataset)\n\ndef eval_model(model, data_loader, criterion, device):\n    model.eval()\n    losses = []\n    correct_predictions = 0\n\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, targets)\n            _, preds = torch.max(outputs, dim=1)\n\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n\n    return np.mean(losses), correct_predictions.double() / len(data_loader.dataset)\n\ndef prepare_loaders(train_df, val_df, test_df, tokenizer, batch_size):\n    train_dataset = SentimentDataset(train_df, tokenizer)\n    val_dataset = SentimentDataset(val_df, tokenizer)\n    test_dataset = SentimentDataset(test_df, tokenizer)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n    return train_loader, val_loader, test_loader","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.033133,"end_time":"2025-07-01T21:51:30.024872","exception":false,"start_time":"2025-07-01T21:51:29.991739","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.118289Z","iopub.execute_input":"2025-07-28T20:01:43.119074Z","iopub.status.idle":"2025-07-28T20:01:43.135220Z","shell.execute_reply.started":"2025-07-28T20:01:43.119052Z","shell.execute_reply":"2025-07-28T20:01:43.134468Z"}},"outputs":[],"execution_count":8},{"id":"a9c8bf87","cell_type":"code","source":"# Enhanced Evaluation Function with all metrics\ndef evaluate_model(model, data_loader, id2label):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    all_probs = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['targets'].to(device)\n            \n            outputs = model(input_ids, attention_mask)\n            probs = torch.nn.functional.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_targets.extend(targets.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    # Use numeric labels instead of strings for metrics calculation\n    classes = list(id2label.values())\n    class_ids = list(id2label.keys())\n    \n    # ==================== PER-CLASS EVALUATION ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"DETAILED PER-CLASS EVALUATION METRICS\")\n    print(\"=\"*60)\n    \n    # Convert to string labels only for display\n    all_pred_labels = [id2label[p] for p in all_preds]\n    all_true_labels = [id2label[t] for t in all_targets]\n    \n    report = classification_report(\n        all_true_labels, \n        all_pred_labels, \n        target_names=classes,\n        digits=4,\n        output_dict=True\n    )\n    \n    class_metrics = pd.DataFrame(report).transpose().drop(['accuracy', 'macro avg', 'weighted avg'])\n    print(\"\\nPer-class metrics:\")\n    print(class_metrics.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    # ==================== OVERALL EVALUATION ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"COMPREHENSIVE OVERALL EVALUATION METRICS\")\n    print(\"=\"*60)\n    \n    # Use numeric labels (all_targets and all_preds) to calculate metrics\n    accuracy = accuracy_score(all_targets, all_preds)\n    balanced_accuracy = balanced_accuracy_score(all_targets, all_preds)\n    f1_macro = f1_score(all_targets, all_preds, average='macro')\n    f1_weighted = f1_score(all_targets, all_preds, average='weighted')\n    kappa = cohen_kappa_score(all_targets, all_preds)\n    mcc = matthews_corrcoef(all_targets, all_preds)\n    lloss = log_loss(all_targets, all_probs, labels=class_ids)\n    h_loss = hamming_loss(all_targets, all_preds)\n    jaccard = jaccard_score(all_targets, all_preds, average='weighted')\n    \n    try:\n        top2_acc = top_k_accuracy_score(all_targets, all_probs, k=2)\n        top3_acc = top_k_accuracy_score(all_targets, all_probs, k=3)\n    except:\n        top2_acc = top3_acc = None\n    \n    # ROC AUC calculation\n    try:\n        if len(classes) == 2:\n            roc_auc = roc_auc_score(all_targets, [p[1] for p in all_probs])\n        else:\n            y_true_bin = label_binarize(all_targets, classes=class_ids)\n            roc_auc = roc_auc_score(y_true_bin, all_probs, multi_class='ovr')\n    except Exception as e:\n        print(f\"Could not calculate ROC AUC: {str(e)}\")\n        roc_auc = None\n    \n    # Precision-Recall AUC\n    try:\n        if len(classes) == 2:\n            precision, recall, _ = precision_recall_curve(all_targets, [p[1] for p in all_probs])\n            pr_auc = auc(recall, precision)\n        else:\n            pr_auc = average_precision_score(\n                label_binarize(all_targets, classes=class_ids),\n                all_probs,\n                average='macro'\n            )\n    except Exception as e:\n        print(f\"Could not calculate PR AUC: {str(e)}\")\n        pr_auc = None\n    \n    # Display overall metrics in a comprehensive table\n    overall_metrics = {\n        'Accuracy': accuracy,\n        'Balanced Accuracy': balanced_accuracy,\n        'Macro F1': f1_macro,\n        'Weighted F1': f1_weighted,\n        'Macro Precision': report['macro avg']['precision'],\n        'Macro Recall': report['macro avg']['recall'],\n        'Cohen Kappa': kappa,\n        'Matthews Corr Coef': mcc,\n        'Log Loss': lloss,\n        'Hamming Loss': h_loss,\n        'Jaccard Score': jaccard,\n    }\n    \n    if roc_auc is not None:\n        overall_metrics['ROC AUC'] = roc_auc\n    if pr_auc is not None:\n        overall_metrics['PR AUC'] = pr_auc\n    if top2_acc is not None:\n        overall_metrics['Top-2 Accuracy'] = top2_acc\n        overall_metrics['Top-3 Accuracy'] = top3_acc\n    \n    overall_df = pd.DataFrame.from_dict(overall_metrics, orient='index', columns=['Value'])\n    print(\"\\nOverall metrics:\")\n    print(overall_df.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    # ==================== VISUALIZATIONS ====================\n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION VISUALIZATIONS\")\n    print(\"=\"*60)\n    \n    # 1. Confusion matrix\n    plt.figure(figsize=(12, 10))\n    cm = confusion_matrix(all_true_labels, all_pred_labels, labels=classes)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=classes, yticklabels=classes)\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n    confusion_matrix_path = os.path.join(log_dir, 'confusion_matrix.png')\n    plt.savefig(confusion_matrix_path)\n    plt.close()\n    print(f\"\\nConfusion matrix saved to {confusion_matrix_path}\")\n    \n    # 2. Precision-Recall Curve\n    plt.figure(figsize=(12, 10))\n    if len(classes) == 2:\n        precision, recall, _ = precision_recall_curve(all_targets, [p[1] for p in all_probs])\n        plt.plot(recall, precision, lw=2, label=f'PR Curve (AUC = {pr_auc:.2f})')\n    else:\n        for i, class_name in enumerate(classes):\n            precision, recall, _ = precision_recall_curve(\n                (np.array(all_targets) == class_ids[i]).astype(int),\n                np.array(all_probs)[:, i]\n            )\n            plt.plot(recall, precision, lw=2, label=f'{class_name}')\n    \n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.legend(loc='best')\n    pr_curve_path = os.path.join(log_dir, 'precision_recall_curve.png')\n    plt.savefig(pr_curve_path)\n    plt.close()\n    print(f\"Precision-Recall curve saved to {pr_curve_path}\")\n    \n    # 3. ROC Curve (for binary or multiclass)\n    if roc_auc is not None:\n        plt.figure(figsize=(12, 10))\n        if len(classes) == 2:\n            fpr, tpr, _ = roc_curve(all_targets, [p[1] for p in all_probs])\n            plt.plot(fpr, tpr, lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n        else:\n            y_true_bin = label_binarize(all_targets, classes=class_ids)\n            for i, class_name in enumerate(classes):\n                fpr, tpr, _ = roc_curve(y_true_bin[:, i], np.array(all_probs)[:, i])\n                plt.plot(fpr, tpr, lw=2, label=f'{class_name}')\n        \n        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.legend(loc='best')\n        roc_curve_path = os.path.join(log_dir, 'roc_curve.png')\n        plt.savefig(roc_curve_path)\n        plt.close()\n        print(f\"ROC curve saved to {roc_curve_path}\")\n    \n    # Log all metrics\n    logging.info(\"\\n=== DETAILED PER-CLASS EVALUATION METRICS ===\")\n    logging.info(\"\\nPer-class metrics:\\n\" + class_metrics.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    logging.info(\"\\n=== COMPREHENSIVE OVERALL EVALUATION METRICS ===\")\n    logging.info(\"\\nOverall metrics:\\n\" + overall_df.to_markdown(tablefmt=\"grid\", floatfmt=\".4f\"))\n    \n    return {\n        'class_metrics': class_metrics,\n        'overall_metrics': overall_metrics,\n        'confusion_matrix': cm,\n        'roc_auc': roc_auc,\n        'pr_auc': pr_auc,\n        'visualizations': {\n            'confusion_matrix': confusion_matrix_path,\n            'pr_curve': pr_curve_path,\n            'roc_curve': roc_curve_path if roc_auc is not None else None\n        }\n    }","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.045365,"end_time":"2025-07-01T21:51:30.093647","exception":false,"start_time":"2025-07-01T21:51:30.048282","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.137192Z","iopub.execute_input":"2025-07-28T20:01:43.137400Z","iopub.status.idle":"2025-07-28T20:01:43.159739Z","shell.execute_reply.started":"2025-07-28T20:01:43.137385Z","shell.execute_reply":"2025-07-28T20:01:43.159050Z"}},"outputs":[],"execution_count":9},{"id":"f02192ce","cell_type":"code","source":"# Train and Evaluate with Optuna\ndef train_and_evaluate(df, test_df, tokenizer, class_weights):\n    def objective(trial):\n        learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n        batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n        n_epochs = trial.suggest_int(\"n_epochs\", 5, 15)\n        \n        logging.info(f\"Trial {trial.number}: lr={learning_rate:.6f}, batch_size={batch_size}, dropout_rate={dropout_rate:.2f}, epochs={n_epochs}\")\n        \n        class SentimentClassifier(nn.Module):\n            def __init__(self, n_classes=3, dropout_rate=dropout_rate):\n                super(SentimentClassifier, self).__init__()\n                self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n                self.drop = nn.Dropout(p=dropout_rate)\n                self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n                nn.init.normal_(self.fc.weight, std=0.02)\n                nn.init.normal_(self.fc.bias, 0)\n\n            def forward(self, input_ids, attention_mask):\n                _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n                output = self.drop(pooled_output)\n                return self.fc(output)\n        \n        skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=86)\n        fold_accuracies = []\n        \n        for fold, (train_index, val_index) in enumerate(skf.split(df, df['sentiment'])):\n            print(f'\\nFold {fold + 1}/{N_SPLITS}')\n            train_df = df.iloc[train_index].reset_index(drop=True)\n            val_df = df.iloc[val_index].reset_index(drop=True)\n            train_loader, val_loader, _ = prepare_loaders(train_df, val_df, test_df, tokenizer, batch_size)\n            \n            model = SentimentClassifier().to(device)\n            criterion = nn.CrossEntropyLoss(weight=class_weights)\n            optimizer = AdamW(model.parameters(), lr=learning_rate)\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * n_epochs)\n            \n            best_val_acc = 0\n            patience = 3\n            epochs_no_improve = 0\n            for epoch in range(n_epochs):\n                train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n                val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n                logging.info(f\"Trial {trial.number}, Fold {fold+1}, Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n                print(f\"Epoch {epoch+1}/{n_epochs} - Val Acc: {val_acc:.4f}\")\n                \n                if val_acc > best_val_acc:\n                    best_val_acc = val_acc.cpu().item()\n                    epochs_no_improve = 0\n                else:\n                    epochs_no_improve += 1\n                    if epochs_no_improve >= patience:\n                        logging.info(f\"Early stopping triggered at epoch {epoch+1} for fold {fold+1}\")\n                        break\n            \n            fold_accuracies.append(best_val_acc)\n        \n        avg_val_acc = np.mean(fold_accuracies)\n        logging.info(f\"Trial {trial.number} completed with average validation accuracy: {avg_val_acc:.4f}\")\n        return avg_val_acc\n    \n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=3)\n    \n    best_trial = study.best_trial\n    logging.info(f\"Best trial: {best_trial.number}\")\n    logging.info(f\"Best validation accuracy: {best_trial.value:.4f}\")\n    logging.info(f\"Best hyperparameters: {best_trial.params}\")\n    \n    best_lr = best_trial.params['learning_rate']\n    best_batch_size = best_trial.params['batch_size']\n    best_dropout_rate = best_trial.params['dropout_rate']\n    best_n_epochs = best_trial.params['n_epochs']\n    \n    logging.info(f\"Training final model with best hyperparameters: lr={best_lr:.6f}, batch_size={best_batch_size}, dropout_rate={best_dropout_rate:.2f}, epochs={best_n_epochs}\")\n    \n    class SentimentClassifier(nn.Module):\n        def __init__(self, n_classes=3, dropout_rate=best_dropout_rate):\n            super(SentimentClassifier, self).__init__()\n            self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n            self.drop = nn.Dropout(p=dropout_rate)\n            self.fc = nn.Linear(self.bert.config.hidden_size, n_classes)\n            nn.init.normal_(self.fc.weight, std=0.02)\n            nn.init.normal_(self.fc.bias, 0)\n\n        def forward(self, input_ids, attention_mask):\n            _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n            output = self.drop(pooled_output)\n            return self.fc(output)\n    \n    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=86)\n    best_accuracy = 0\n    best_model_path = None\n    \n    for fold, (train_index, val_index) in enumerate(skf.split(df, df['sentiment'])):\n        print(f'\\nFinal Training - Fold {fold + 1}/{N_SPLITS}')\n        train_df = df.iloc[train_index].reset_index(drop=True)\n        val_df = df.iloc[val_index].reset_index(drop=True)\n        train_loader, val_loader, _ = prepare_loaders(train_df, val_df, test_df, tokenizer, best_batch_size)\n        \n        model = SentimentClassifier().to(device)\n        criterion = nn.CrossEntropyLoss(weight=class_weights)\n        optimizer = AdamW(model.parameters(), lr=best_lr)\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * best_n_epochs)\n        \n        best_val_acc = 0\n        patience = 3\n        epochs_no_improve = 0\n        for epoch in range(best_n_epochs):\n            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n            val_loss, val_acc = eval_model(model, val_loader, criterion, device)\n            logging.info(f\"Final Training, Fold {fold+1}, Epoch {epoch+1}/{best_n_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n            print(f\"Epoch {epoch+1}/{best_n_epochs} - Val Acc: {val_acc:.4f}\")\n            \n            if val_acc > best_val_acc:\n                best_val_acc = val_acc.cpu().item()\n                epochs_no_improve = 0\n                if best_val_acc > best_accuracy:\n                    best_accuracy = best_val_acc\n                    best_model_path = os.path.join(log_dir, f'PhoBERT_sentiment_temp.bin')\n                    torch.save(model.state_dict(), best_model_path)\n                    logging.info(f\"Saved best model at fold {fold+1}, epoch {epoch+1} with accuracy {val_acc:.4f}\")\n            else:\n                epochs_no_improve += 1\n                if epochs_no_improve >= patience:\n                    logging.info(f\"Early stopping triggered at epoch {epoch+1} for fold {fold+1}\")\n                    break\n    \n    model.load_state_dict(torch.load(best_model_path))\n    os.remove(best_model_path)\n    final_model_path = os.path.join(log_dir, 'PhoBERT_summary_sentiment_optuna.bin')\n    torch.save(model.state_dict(), final_model_path)\n    logging.info(f\"Final best model saved as PhoBERT_summary_sentiment_optuna.bin with accuracy {best_accuracy:.4f}\")\n    return model\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.032509,"end_time":"2025-07-01T21:51:30.149793","exception":false,"start_time":"2025-07-01T21:51:30.117284","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.160455Z","iopub.execute_input":"2025-07-28T20:01:43.160649Z","iopub.status.idle":"2025-07-28T20:01:43.185519Z","shell.execute_reply.started":"2025-07-28T20:01:43.160627Z","shell.execute_reply":"2025-07-28T20:01:43.184977Z"}},"outputs":[],"execution_count":10},{"id":"8c11111a","cell_type":"code","source":"# Inference Function\ndef predict_sentiment(text, model, tokenizer, id2label):\n    dataset = SentimentDataset(pd.DataFrame({'text': [text], 'sentiment': [0]}), tokenizer)\n    data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n\n    model.eval()\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            _, pred = torch.max(outputs, dim=1)\n    return id2label[pred.item()]","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.029557,"end_time":"2025-07-01T21:51:30.203075","exception":false,"start_time":"2025-07-01T21:51:30.173518","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.186089Z","iopub.execute_input":"2025-07-28T20:01:43.186368Z","iopub.status.idle":"2025-07-28T20:01:43.207594Z","shell.execute_reply.started":"2025-07-28T20:01:43.186329Z","shell.execute_reply":"2025-07-28T20:01:43.206932Z"}},"outputs":[],"execution_count":11},{"id":"1db0bea6","cell_type":"code","source":"# Zip output files for download\ndef zip_and_download_output_files():\n    output_zip = os.path.join(log_dir, 'output_files.zip')\n    output_files = [\n        'training_summary_sentiment_log_v1.txt',\n        'data_processed_for_summary_sentiment.csv',\n        'PhoBERT_summary_sentiment_v1.bin',\n        'confusion_matrix.png',\n        'precision_recall_curve.png',\n        'roc_curve.png'\n    ]\n    \n    # Only include existing files\n    existing_files = [f for f in output_files if os.path.exists(os.path.join(log_dir, f))]\n    missing_files = set(output_files) - set(existing_files)\n    \n    if missing_files:\n        logging.warning(f\"Missing files: {missing_files}\")\n    \n    try:\n        with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for file in existing_files:\n                file_path = os.path.join(log_dir, file)\n                zipf.write(file_path, file)\n                logging.info(f\"Added {file} to zip archive\")\n        \n        if os.path.exists(output_zip):\n            logging.info(f\"Zip file created at {output_zip}\")\n            \n            # Automatic download\n            print(\"\\n\" + \"=\"*60)\n            print(\"AUTOMATICALLY DOWNLOADING OUTPUT FILES\")\n            print(\"=\"*60)\n            \n            # For Kaggle\n            if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n                print(\"In Kaggle environment, please download manually:\")\n                display(FileLink('output_files.zip'))\n            # For Google Colab\n            else:\n                print(\"Downloading output files automatically...\")\n                from google.colab import files\n                files.download(output_zip)\n            \n            return output_zip\n        else:\n            logging.error(\"Failed to create zip file\")\n            return None\n    except Exception as e:\n        logging.error(f\"Error creating zip: {e}\")\n        return None","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.031911,"end_time":"2025-07-01T21:51:30.259046","exception":false,"start_time":"2025-07-01T21:51:30.227135","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.208285Z","iopub.execute_input":"2025-07-28T20:01:43.208541Z","iopub.status.idle":"2025-07-28T20:01:43.229347Z","shell.execute_reply.started":"2025-07-28T20:01:43.208520Z","shell.execute_reply":"2025-07-28T20:01:43.228722Z"}},"outputs":[],"execution_count":12},{"id":"7673270f","cell_type":"code","source":"# Main Execution\nif __name__ == \"__main__\":\n    try:\n        xlsx_path = '/kaggle/input/data-news-v3/data_news_v3.xlsx'\n        if not os.path.exists(xlsx_path):\n            raise FileNotFoundError(f\"File {xlsx_path} not found!\")\n        print(f\"Found data file at {xlsx_path}\")\n        print(\"Loading data...\")\n        df_processed = load_original_data(xlsx_path)\n        print(\"Cleaning data...\")\n        df_processed = clean_data(df_processed)\n        print(\"Processing labels...\")\n        df_processed, label2id, id2label, class_weights = process_labels(df_processed)\n        print(\"Loading tokenizer...\")\n        tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n        print(\"Tokenizer loaded successfully.\")\n        print(\"Tokenizing data...\")\n        df_processed = tokenize_data(df_processed, tokenizer)\n\n        processed_data_path = os.path.join(log_dir, 'data_processed_for_summary_sentiment.csv')\n        df_processed.to_csv(processed_data_path, index=False)\n        logging.info(f\"Saved processed data with shape: {df_processed.shape}\")\n\n        summary_lengths = df_processed['text'].str.len()\n        token_lengths = [len(t) for t in df_processed['tokenized']]\n        logging.info(f\"Summary length stats: Min={summary_lengths.min()}, Max={summary_lengths.max()}, Mean={summary_lengths.mean():.2f}\")\n        logging.info(f\"Token length stats: Min={min(token_lengths)}, Max={max(token_lengths)}, Mean={np.mean(token_lengths):.2f}\")\n        logging.info(f\"Processing config: max_len={MAX_LEN}, n_splits={N_SPLITS}\")\n\n        train_val_df, test_df = train_test_split(df_processed, test_size=0.2, stratify=df_processed['sentiment'], random_state=86)\n        logging.info(f\"Data split: Train+Val={len(train_val_df)}, Test={len(test_df)}\")\n\n        print(\"Starting training with Optuna optimization...\")\n        model = train_and_evaluate(train_val_df, test_df, tokenizer, class_weights)\n\n        print(\"Evaluating model...\")\n        _, _, test_loader = prepare_loaders(train_val_df, train_val_df, test_df, tokenizer, batch_size=16)\n        evaluation_results = evaluate_model(model, test_loader, id2label)\n\n        sample_text = \"Đầu tư nước ngoài, dù đã tăng trưởng (FDI đạt 8,9 tỷ USD trong 5 tháng đầu năm), nhưng vẫn ghi nhận dòng vốn ngoại rút mạnh do lo ngại rủi ro thương mại, dù được kỳ vọng sẽ phục hồi khi các thị trường nâng hạng.\"\n        predicted_sentiment = predict_sentiment(sample_text, model, tokenizer, id2label)\n        print(f\"\\nSample text: {sample_text}\")\n        print(f\"Predicted sentiment: {predicted_sentiment}\")\n        logging.info(f\"Inference test: Text='{sample_text}', Predicted='{predicted_sentiment}'\")\n\n        print(\"\\nPreparing output files for download...\")\n        zip_and_download_output_files()\n\n    except Exception as e:\n        logging.error(f\"Error in main execution: {e}\", exc_info=True)\n        raise","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5650.205811,"end_time":"2025-07-01T23:25:40.488733","exception":false,"start_time":"2025-07-01T21:51:30.282922","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T20:01:43.230288Z","iopub.execute_input":"2025-07-28T20:01:43.230550Z","iopub.status.idle":"2025-07-29T03:11:14.414029Z","shell.execute_reply.started":"2025-07-28T20:01:43.230535Z","shell.execute_reply":"2025-07-29T03:11:14.413365Z"}},"outputs":[{"name":"stdout","text":"Found data file at /kaggle/input/data-news-v3/data_news_v3.xlsx\nLoading data...\nCleaning data...\nProcessing labels...\nLoading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75f5d1922881493fb9669538e967d45d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9160748362e8462eba3daaa3b5f5b986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4b0348f5df493b86b813e92c404426"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae124c452fa46719b4121296bce6397"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded successfully.\nTokenizing data...\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-28 20:02:10,264] A new study created in memory with name: no-name-b1cb1ccb-57f0-4895-aca2-995486ee6e9f\n","output_type":"stream"},{"name":"stdout","text":"Starting training with Optuna optimization...\n\nFold 1/3\n","output_type":"stream"},{"name":"stderr","text":"2025-07-28 20:02:27.111219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753732947.483045      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753732947.589265      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e462a3841e76433d80dec1ab8f8a717a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17d81f8c1b6d405f9952de5f94636b70"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Val Acc: 0.7327\nEpoch 2/5 - Val Acc: 0.7261\nEpoch 3/5 - Val Acc: 0.7855\nEpoch 4/5 - Val Acc: 0.7824\nEpoch 5/5 - Val Acc: 0.7761\n\nFold 2/3\nEpoch 1/5 - Val Acc: 0.7528\nEpoch 2/5 - Val Acc: 0.7491\nEpoch 3/5 - Val Acc: 0.7645\nEpoch 4/5 - Val Acc: 0.7651\nEpoch 5/5 - Val Acc: 0.7711\n\nFold 3/3\nEpoch 1/5 - Val Acc: 0.6566\nEpoch 2/5 - Val Acc: 0.7629\nEpoch 3/5 - Val Acc: 0.7610\nEpoch 4/5 - Val Acc: 0.7752\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-28 21:23:30,572] Trial 0 finished with value: 0.7772536687631026 and parameters: {'learning_rate': 4.63830821446872e-05, 'batch_size': 16, 'dropout_rate': 0.4086165623885558, 'n_epochs': 5}. Best is trial 0 with value: 0.7772536687631026.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Val Acc: 0.7748\n\nFold 1/3\nEpoch 1/9 - Val Acc: 0.7695\nEpoch 2/9 - Val Acc: 0.7220\nEpoch 3/9 - Val Acc: 0.7896\nEpoch 4/9 - Val Acc: 0.7843\nEpoch 5/9 - Val Acc: 0.7708\nEpoch 6/9 - Val Acc: 0.7673\n\nFold 2/3\nEpoch 1/9 - Val Acc: 0.7443\nEpoch 2/9 - Val Acc: 0.7610\nEpoch 3/9 - Val Acc: 0.7739\nEpoch 4/9 - Val Acc: 0.7780\nEpoch 5/9 - Val Acc: 0.7642\nEpoch 6/9 - Val Acc: 0.7660\nEpoch 7/9 - Val Acc: 0.7736\n\nFold 3/3\nEpoch 1/9 - Val Acc: 0.7635\nEpoch 2/9 - Val Acc: 0.7676\nEpoch 3/9 - Val Acc: 0.7830\nEpoch 4/9 - Val Acc: 0.7421\nEpoch 5/9 - Val Acc: 0.7660\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-28 23:05:46,420] Trial 1 finished with value: 0.7835429769392034 and parameters: {'learning_rate': 3.300672680352246e-05, 'batch_size': 16, 'dropout_rate': 0.24189763081363186, 'n_epochs': 9}. Best is trial 1 with value: 0.7835429769392034.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/9 - Val Acc: 0.7720\n\nFold 1/3\nEpoch 1/13 - Val Acc: 0.7811\nEpoch 2/13 - Val Acc: 0.7840\nEpoch 3/13 - Val Acc: 0.7808\nEpoch 4/13 - Val Acc: 0.7541\nEpoch 5/13 - Val Acc: 0.7777\n\nFold 2/3\nEpoch 1/13 - Val Acc: 0.7164\nEpoch 2/13 - Val Acc: 0.7437\nEpoch 3/13 - Val Acc: 0.7478\nEpoch 4/13 - Val Acc: 0.7689\nEpoch 5/13 - Val Acc: 0.7654\nEpoch 6/13 - Val Acc: 0.7374\nEpoch 7/13 - Val Acc: 0.7692\nEpoch 8/13 - Val Acc: 0.7494\nEpoch 9/13 - Val Acc: 0.7698\nEpoch 10/13 - Val Acc: 0.7701\nEpoch 11/13 - Val Acc: 0.7664\nEpoch 12/13 - Val Acc: 0.7610\nEpoch 13/13 - Val Acc: 0.7676\n\nFold 3/3\nEpoch 1/13 - Val Acc: 0.7305\nEpoch 2/13 - Val Acc: 0.7469\nEpoch 3/13 - Val Acc: 0.7770\nEpoch 4/13 - Val Acc: 0.7701\nEpoch 5/13 - Val Acc: 0.7726\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-07-29 01:12:12,510] Trial 2 finished with value: 0.7770440251572327 and parameters: {'learning_rate': 1.86963250778752e-05, 'batch_size': 32, 'dropout_rate': 0.1849223660849616, 'n_epochs': 13}. Best is trial 1 with value: 0.7835429769392034.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/13 - Val Acc: 0.7673\n\nFinal Training - Fold 1/3\nEpoch 1/9 - Val Acc: 0.7616\nEpoch 2/9 - Val Acc: 0.7855\nEpoch 3/9 - Val Acc: 0.7789\nEpoch 4/9 - Val Acc: 0.7755\nEpoch 5/9 - Val Acc: 0.7777\n\nFinal Training - Fold 2/3\nEpoch 1/9 - Val Acc: 0.7619\nEpoch 2/9 - Val Acc: 0.7698\nEpoch 3/9 - Val Acc: 0.7645\nEpoch 4/9 - Val Acc: 0.7657\nEpoch 5/9 - Val Acc: 0.7717\nEpoch 6/9 - Val Acc: 0.7717\nEpoch 7/9 - Val Acc: 0.7664\nEpoch 8/9 - Val Acc: 0.7660\n\nFinal Training - Fold 3/3\nEpoch 1/9 - Val Acc: 0.7638\nEpoch 2/9 - Val Acc: 0.7626\nEpoch 3/9 - Val Acc: 0.7645\nEpoch 4/9 - Val Acc: 0.7358\nEpoch 5/9 - Val Acc: 0.7708\nEpoch 6/9 - Val Acc: 0.7667\nEpoch 7/9 - Val Acc: 0.7711\nEpoch 8/9 - Val Acc: 0.7701\nEpoch 9/9 - Val Acc: 0.7704\nEvaluating model...\n\n============================================================\nDETAILED PER-CLASS EVALUATION METRICS\n============================================================\n\nPer-class metrics:\n+----------+-------------+----------+------------+-----------+\n|          |   precision |   recall |   f1-score |   support |\n+==========+=============+==========+============+===========+\n| Positive |      0.7812 |   0.8717 |     0.8240 |  639.0000 |\n+----------+-------------+----------+------------+-----------+\n| Negative |      0.6393 |   0.4845 |     0.5512 |  611.0000 |\n+----------+-------------+----------+------------+-----------+\n| Neutral  |      0.8298 |   0.8838 |     0.8559 | 1136.0000 |\n+----------+-------------+----------+------------+-----------+\n\n============================================================\nCOMPREHENSIVE OVERALL EVALUATION METRICS\n============================================================\n\nOverall metrics:\n+--------------------+---------+\n|                    |   Value |\n+====================+=========+\n| Accuracy           |  0.7783 |\n+--------------------+---------+\n| Balanced Accuracy  |  0.7466 |\n+--------------------+---------+\n| Macro F1           |  0.7437 |\n+--------------------+---------+\n| Weighted F1        |  0.7693 |\n+--------------------+---------+\n| Macro Precision    |  0.7501 |\n+--------------------+---------+\n| Macro Recall       |  0.7466 |\n+--------------------+---------+\n| Cohen Kappa        |  0.6474 |\n+--------------------+---------+\n| Matthews Corr Coef |  0.6505 |\n+--------------------+---------+\n| Log Loss           |  0.5514 |\n+--------------------+---------+\n| Hamming Loss       |  0.2217 |\n+--------------------+---------+\n| Jaccard Score      |  0.6413 |\n+--------------------+---------+\n| ROC AUC            |  0.9060 |\n+--------------------+---------+\n| PR AUC             |  0.8198 |\n+--------------------+---------+\n| Top-2 Accuracy     |  0.9606 |\n+--------------------+---------+\n| Top-3 Accuracy     |  1.0000 |\n+--------------------+---------+\n\n============================================================\nEVALUATION VISUALIZATIONS\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1802: UndefinedMetricWarning: 'k' (3) greater than or equal to 'n_classes' (3) will result in a perfect score and is therefore meaningless.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nConfusion matrix saved to /kaggle/working/confusion_matrix.png\nPrecision-Recall curve saved to /kaggle/working/precision_recall_curve.png\n","output_type":"stream"},{"name":"stderr","text":"2025-07-29 03:11:13,233 - WARNING - Missing files: {'PhoBERT_summary_sentiment_v1.bin', 'training_summary_sentiment_log_v1.txt'}\n","output_type":"stream"},{"name":"stdout","text":"ROC curve saved to /kaggle/working/roc_curve.png\n\nSample text: Đầu tư nước ngoài, dù đã tăng trưởng (FDI đạt 8,9 tỷ USD trong 5 tháng đầu năm), nhưng vẫn ghi nhận dòng vốn ngoại rút mạnh do lo ngại rủi ro thương mại, dù được kỳ vọng sẽ phục hồi khi các thị trường nâng hạng.\nPredicted sentiment: Negative\n\nPreparing output files for download...\n\n============================================================\nAUTOMATICALLY DOWNLOADING OUTPUT FILES\n============================================================\nIn Kaggle environment, please download manually:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output_files.zip","text/html":"<a href='output_files.zip' target='_blank'>output_files.zip</a><br>"},"metadata":{}}],"execution_count":13}]}