{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12565028,"sourceType":"datasetVersion","datasetId":7934646}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# *Vietnamese News Industry Classification with XLM-RoBERTa*\n## This notebook fine-tunes XLM-RoBERTa for classifying the industry of Vietnamese news summaries.\n* Dataset: 5179 samples","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!pip install -q transformers datasets evaluate accelerate scikit-learn pandas matplotlib seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:06:37.391676Z","iopub.execute_input":"2025-07-24T14:06:37.391940Z","iopub.status.idle":"2025-07-24T14:07:52.575973Z","shell.execute_reply.started":"2025-07-24T14:06:37.391913Z","shell.execute_reply":"2025-07-24T14:07:52.575286Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport zipfile\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n    EarlyStoppingCallback\n)\nfrom datasets import Dataset, DatasetDict\nimport evaluate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport logging","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:07:52.577819Z","iopub.execute_input":"2025-07-24T14:07:52.578050Z","iopub.status.idle":"2025-07-24T14:08:20.046226Z","shell.execute_reply.started":"2025-07-24T14:07:52.578029Z","shell.execute_reply":"2025-07-24T14:08:20.045420Z"}},"outputs":[{"name":"stderr","text":"2025-07-24 14:08:06.378109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753366086.569347      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753366086.623265      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Configuration\nclass Config:\n    MODEL_NAME = \"xlm-roberta-base\"\n    SEED = 42\n    BATCH_SIZE = 8  # Reduced to avoid GPU memory issues\n    GRADIENT_ACCUMULATION_STEPS = 2  # Adjusted for effective batch size of 16\n    LEARNING_RATE = 2e-5\n    NUM_EPOCHS = 10\n    MAX_LENGTH = 256\n    WEIGHT_DECAY = 0.01\n    OUTPUT_DIR = \"./xlm-roberta-industry-complete\"\n    LOGGING_STEPS = 10  # Increased frequency for better monitoring\n    SAVE_TOTAL_LIMIT = 2\n    INDUSTRY_MAP = {'Finance': 0, 'Technology': 1, 'Healthcare': 2, 'Energy': 3, 'Other': 4}\n    REVERSE_INDUSTRY_MAP = {0: 'Finance', 1: 'Technology', 2: 'Healthcare', 3: 'Energy', 4: 'Other'}\n    EARLY_STOPPING_PATIENCE = 3\n    LR_SCHEDULER_TYPE = \"cosine\"\n    WARMUP_RATIO = 0.1\n    USE_CLASS_WEIGHTS = True\n    DATA_PATH = \"/kaggle/input/data-news-v1/data_news_v1.xlsx\"\n\nconfig = Config()\n\n# Create output directory\nos.makedirs(config.OUTPUT_DIR, exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:20.046945Z","iopub.execute_input":"2025-07-24T14:08:20.047373Z","iopub.status.idle":"2025-07-24T14:08:20.052753Z","shell.execute_reply.started":"2025-07-24T14:08:20.047354Z","shell.execute_reply":"2025-07-24T14:08:20.052079Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set up logging with error handling\ntry:\n    logging.basicConfig(\n        filename=os.path.join(config.OUTPUT_DIR, 'training.log'),\n        level=logging.DEBUG,  # Increased verbosity\n        format='%(asctime)s - %(levelname)s - %(message)s'\n    )\n    logger = logging.getLogger(__name__)\n    logger.info(\"Logging initialized successfully\")\nexcept PermissionError:\n    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n    logger = logging.getLogger(__name__)\n    logger.info(\"Fallback to console logging due to permission error for file: %s\", os.path.join(config.OUTPUT_DIR, 'training.log'))\nexcept Exception as e:\n    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n    logger = logging.getLogger(__name__)\n    logger.info(\"Logging setup failed with error: %s. Fallback to console logging.\", str(e))\n\n# Set random seed\ntorch.manual_seed(config.SEED)\nnp.random.seed(config.SEED)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:20.053514Z","iopub.execute_input":"2025-07-24T14:08:20.054251Z","iopub.status.idle":"2025-07-24T14:08:20.077467Z","shell.execute_reply.started":"2025-07-24T14:08:20.054223Z","shell.execute_reply":"2025-07-24T14:08:20.076913Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Custom Trainer with class weights\nclass WeightedTrainer(Trainer):\n    def __init__(self, class_weights=None, **kwargs):\n        super().__init__(**kwargs)\n        self.class_weights = class_weights\n        \n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n        labels = labels.long()\n        \n        if self.class_weights is not None:\n            weights = torch.tensor(self.class_weights, device=logits.device, dtype=torch.float32)\n            loss_fct = torch.nn.CrossEntropyLoss(weight=weights)\n        else:\n            loss_fct = torch.nn.CrossEntropyLoss()\n            \n        loss = loss_fct(logits, labels)\n        return (loss, outputs) if return_outputs else loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:20.078130Z","iopub.execute_input":"2025-07-24T14:08:20.078350Z","iopub.status.idle":"2025-07-24T14:08:20.084238Z","shell.execute_reply.started":"2025-07-24T14:08:20.078333Z","shell.execute_reply":"2025-07-24T14:08:20.083558Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load and explore dataset\ndef load_and_explore_data(file_path):\n    logger.info(\"Loading dataset...\")\n    df = pd.read_excel(file_path)\n    \n    df['label'] = df['industry'].map(config.INDUSTRY_MAP)\n    \n    with open(os.path.join(config.OUTPUT_DIR, 'dataset_info.txt'), 'w') as f:\n        f.write(f\"Total samples: {len(df)}\\n\")\n        f.write(\"\\nIndustry distribution:\\n\")\n        f.write(df['industry'].value_counts().to_string())\n    \n    plt.figure(figsize=(8, 5))\n    class_dist = df['industry'].value_counts()\n    sns.barplot(x=class_dist.index, y=class_dist.values)\n    plt.title('Industry Distribution')\n    plt.ylabel('Count')\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'industry_distribution.png'))\n    plt.close()\n    \n    df['text_length'] = df['summary'].apply(lambda x: len(x.split()))\n    \n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    sns.histplot(df['text_length'], bins=30)\n    plt.title('Text Length Distribution')\n    \n    plt.subplot(1, 2, 2)\n    sns.boxplot(x='industry', y='text_length', data=df)\n    plt.title('Text Length by Industry')\n    plt.savefig(os.path.join(config.OUTPUT_DIR, 'text_length_distribution.png'))\n    plt.close()\n    \n    return df\n\ndf = load_and_explore_data(config.DATA_PATH)\ndf = df.dropna()\n\nif config.USE_CLASS_WEIGHTS:\n    class_weights = compute_class_weight(\n        'balanced', \n        classes=np.unique(df['label']),\n        y=df['label']\n    )\n    config.CLASS_WEIGHTS = class_weights.tolist()\n    logger.info(f\"Class weights: {config.CLASS_WEIGHTS}\")\nelse:\n    config.CLASS_WEIGHTS = None\n\ntokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:20.084932Z","iopub.execute_input":"2025-07-24T14:08:20.085159Z","iopub.status.idle":"2025-07-24T14:08:25.846238Z","shell.execute_reply.started":"2025-07-24T14:08:20.085134Z","shell.execute_reply":"2025-07-24T14:08:25.845414Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab291d4e6aa34d95b2181ede22d91dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"257d37f03d744728808081d5f38fa109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d771b024477c4423922b7157f23c071e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f09b73c9f9246e1af767ee1c9bbc956"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Analyze token lengths\ndef analyze_token_lengths(texts, tokenizer, max_length):\n    lengths = []\n    for text in texts:\n        tokens = tokenizer(text, truncation=True, max_length=max_length)[\"input_ids\"]\n        lengths.append(len(tokens))\n    return lengths\n\ntoken_lengths = analyze_token_lengths(df['summary'], tokenizer, config.MAX_LENGTH)\n\nplt.figure(figsize=(10, 5))\nsns.histplot(token_lengths, bins=30)\nplt.title('Token Length Distribution')\nplt.axvline(x=config.MAX_LENGTH, color='r', linestyle='--', label='Max Length')\nplt.legend()\nplt.savefig(os.path.join(config.OUTPUT_DIR, 'token_length_distribution.png'))\nplt.close()\n\nlogger.info(f\"Percentage of texts within max length: {sum(np.array(token_lengths) <= config.MAX_LENGTH) / len(token_lengths):.2%}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:25.848533Z","iopub.execute_input":"2025-07-24T14:08:25.849159Z","iopub.status.idle":"2025-07-24T14:08:27.370719Z","shell.execute_reply.started":"2025-07-24T14:08:25.849127Z","shell.execute_reply":"2025-07-24T14:08:27.369484Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Preprocess function\ndef preprocess_function(examples):\n    return tokenizer(\n        examples[\"summary\"],\n        truncation=True,\n        max_length=config.MAX_LENGTH,\n        padding=\"max_length\"\n    )\n\n# Split data\ntrain_df, temp_df = train_test_split(\n    df,\n    test_size=0.2,\n    random_state=config.SEED,\n    stratify=df['label']\n)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,\n    random_state=config.SEED,\n    stratify=temp_df['label']\n)\n\ntrain_dataset = Dataset.from_pandas(train_df[['summary', 'industry', 'label']])\nval_dataset = Dataset.from_pandas(val_df[['summary', 'industry', 'label']])\ntest_dataset = Dataset.from_pandas(test_df[['summary', 'industry', 'label']])\n\ndataset = DatasetDict({\n    \"train\": train_dataset,\n    \"validation\": val_dataset,\n    \"test\": test_dataset\n})\n\ntokenized_datasets = dataset.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=[\"summary\", \"industry\"]\n)\n\nwith open(os.path.join(config.OUTPUT_DIR, 'data_splits.txt'), 'w') as f:\n    f.write(f\"Train samples: {len(train_df)}\\n\")\n    f.write(f\"Validation samples: {len(val_df)}\\n\")\n    f.write(f\"Test samples: {len(test_df)}\\n\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    config.MODEL_NAME,\n    num_labels=5\n)\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:27.371560Z","iopub.execute_input":"2025-07-24T14:08:27.371850Z","iopub.status.idle":"2025-07-24T14:08:33.406358Z","shell.execute_reply.started":"2025-07-24T14:08:27.371817Z","shell.execute_reply":"2025-07-24T14:08:33.405755Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2133 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e820bc9c2b74a61be0cd1c6781bfc97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9728253eb045453ca5f8ff5327fad3b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56458e5668714f4ab0f783b0bc96b9c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94267a38c2344c04a9b524aee5081ec7"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Metrics\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    accuracy = accuracy_score(labels, predictions)\n    f1_micro = f1_score(labels, predictions, average='micro')\n    f1_macro = f1_score(labels, predictions, average='macro')\n    f1_weighted = f1_score(labels, predictions, average='weighted')\n    \n    report = classification_report(\n        labels,\n        predictions,\n        target_names=['Finance', 'Technology', 'Healthcare', 'Energy', 'Other'],\n        output_dict=True\n    )\n    \n    metrics = {\n        'accuracy': accuracy,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro,\n        'f1_weighted': f1_weighted,\n        'finance_precision': report['Finance']['precision'],\n        'finance_recall': report['Finance']['recall'],\n        'finance_f1': report['Finance']['f1-score'],\n        'technology_precision': report['Technology']['precision'],\n        'technology_recall': report['Technology']['recall'],\n        'technology_f1': report['Technology']['f1-score'],\n        'healthcare_precision': report['Healthcare']['precision'],\n        'healthcare_recall': report['Healthcare']['recall'],\n        'healthcare_f1': report['Healthcare']['f1-score'],\n        'energy_precision': report['Energy']['precision'],\n        'energy_recall': report['Energy']['recall'],\n        'energy_f1': report['Energy']['f1-score'],\n        'other_precision': report['Other']['precision'],\n        'other_recall': report['Other']['recall'],\n        'other_f1': report['Other']['f1-score']\n    }\n    \n    logger.info(f\"Evaluation metrics: {metrics}\")\n    \n    return metrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:33.407115Z","iopub.execute_input":"2025-07-24T14:08:33.407330Z","iopub.status.idle":"2025-07-24T14:08:33.413887Z","shell.execute_reply.started":"2025-07-24T14:08:33.407312Z","shell.execute_reply":"2025-07-24T14:08:33.413134Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=config.OUTPUT_DIR,\n    run_name=f\"xlm-roberta-industry-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",\n    eval_strategy=\"steps\",\n    eval_steps=100,\n    logging_steps=config.LOGGING_STEPS,\n    save_steps=100,\n    save_total_limit=config.SAVE_TOTAL_LIMIT,\n    learning_rate=config.LEARNING_RATE,\n    per_device_train_batch_size=config.BATCH_SIZE,\n    per_device_eval_batch_size=config.BATCH_SIZE,\n    gradient_accumulation_steps=config.GRADIENT_ACCUMULATION_STEPS,\n    num_train_epochs=config.NUM_EPOCHS,\n    weight_decay=config.WEIGHT_DECAY,\n    lr_scheduler_type=config.LR_SCHEDULER_TYPE,\n    warmup_ratio=config.WARMUP_RATIO,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_f1_macro\",\n    greater_is_better=True,\n    fp16=True,\n    logging_dir=\"./logs\",\n    seed=config.SEED,\n    report_to=\"none\",  # Disable wandb logging\n    log_level=\"debug\"  # Increase logging verbosity\n)\n\n# Initialize Trainer\ntrainer = WeightedTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    class_weights=config.CLASS_WEIGHTS,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=config.EARLY_STOPPING_PATIENCE)]\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:33.414793Z","iopub.execute_input":"2025-07-24T14:08:33.415054Z","iopub.status.idle":"2025-07-24T14:08:34.954894Z","shell.execute_reply.started":"2025-07-24T14:08:33.415028Z","shell.execute_reply":"2025-07-24T14:08:34.954161Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1477917787.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n  super().__init__(**kwargs)\nUsing auto half precision backend\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Check GPU memory before training\nlogger.info(f\"GPU available: {torch.cuda.is_available()}\")\nlogger.info(f\"GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated, {torch.cuda.memory_reserved() / 1024**3:.2f} GB reserved\")\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nprint(f\"GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB allocated, {torch.cuda.memory_reserved() / 1024**3:.2f} GB reserved\")\n\n# Start training with error handling\ntry:\n    logger.info(\"Starting training...\")\n    print(\"Starting training...\")\n    train_result = trainer.train()\nexcept Exception as e:\n    logger.error(f\"Training failed with error: {str(e)}\")\n    print(f\"Training failed with error: {str(e)}\")\n    raise e\n\n# Save training metrics\nmetrics = train_result.metrics\ntrainer.save_metrics(\"train\", metrics)\nlogger.info(f\"Training metrics: {metrics}\")\n\n# Save the final model\ntrainer.save_model(config.OUTPUT_DIR)\ntokenizer.save_pretrained(config.OUTPUT_DIR)\nlogger.info(f\"Model saved to {config.OUTPUT_DIR}\")\n\n# Save training arguments\ntrainer.save_state()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:08:34.955993Z","iopub.execute_input":"2025-07-24T14:08:34.956275Z","iopub.status.idle":"2025-07-24T14:24:21.182485Z","shell.execute_reply.started":"2025-07-24T14:08:34.956250Z","shell.execute_reply":"2025-07-24T14:24:21.181677Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 16\nThe following columns in the Training set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 2,133\n  Num Epochs = 10\n  Instantaneous batch size per device = 8\n  Training with DataParallel so batch size has been adjusted to: 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 2\n  Total optimization steps = 670\n  Number of trainable parameters = 278,047,493\n","output_type":"stream"},{"name":"stdout","text":"GPU available: True\nGPU memory: 1.04 GB allocated, 1.09 GB reserved\nStarting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='670' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [670/670 15:39, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n      <th>F1 Weighted</th>\n      <th>Finance Precision</th>\n      <th>Finance Recall</th>\n      <th>Finance F1</th>\n      <th>Technology Precision</th>\n      <th>Technology Recall</th>\n      <th>Technology F1</th>\n      <th>Healthcare Precision</th>\n      <th>Healthcare Recall</th>\n      <th>Healthcare F1</th>\n      <th>Energy Precision</th>\n      <th>Energy Recall</th>\n      <th>Energy F1</th>\n      <th>Other Precision</th>\n      <th>Other Recall</th>\n      <th>Other F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.774500</td>\n      <td>0.650076</td>\n      <td>0.726592</td>\n      <td>0.726592</td>\n      <td>0.687299</td>\n      <td>0.739040</td>\n      <td>0.888889</td>\n      <td>0.711111</td>\n      <td>0.790123</td>\n      <td>0.404762</td>\n      <td>0.850000</td>\n      <td>0.548387</td>\n      <td>0.393939</td>\n      <td>1.000000</td>\n      <td>0.565217</td>\n      <td>0.786885</td>\n      <td>0.888889</td>\n      <td>0.834783</td>\n      <td>0.881356</td>\n      <td>0.577778</td>\n      <td>0.697987</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.507900</td>\n      <td>0.564391</td>\n      <td>0.797753</td>\n      <td>0.797753</td>\n      <td>0.773005</td>\n      <td>0.800481</td>\n      <td>0.831461</td>\n      <td>0.822222</td>\n      <td>0.826816</td>\n      <td>0.600000</td>\n      <td>0.750000</td>\n      <td>0.666667</td>\n      <td>0.565217</td>\n      <td>1.000000</td>\n      <td>0.722222</td>\n      <td>0.920000</td>\n      <td>0.851852</td>\n      <td>0.884615</td>\n      <td>0.812500</td>\n      <td>0.722222</td>\n      <td>0.764706</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.245400</td>\n      <td>0.654852</td>\n      <td>0.808989</td>\n      <td>0.808989</td>\n      <td>0.782815</td>\n      <td>0.811345</td>\n      <td>0.829545</td>\n      <td>0.811111</td>\n      <td>0.820225</td>\n      <td>0.652174</td>\n      <td>0.750000</td>\n      <td>0.697674</td>\n      <td>0.611111</td>\n      <td>0.846154</td>\n      <td>0.709677</td>\n      <td>0.938776</td>\n      <td>0.851852</td>\n      <td>0.893204</td>\n      <td>0.797753</td>\n      <td>0.788889</td>\n      <td>0.793296</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.158100</td>\n      <td>0.694694</td>\n      <td>0.805243</td>\n      <td>0.805243</td>\n      <td>0.786909</td>\n      <td>0.806089</td>\n      <td>0.789474</td>\n      <td>0.833333</td>\n      <td>0.810811</td>\n      <td>0.681818</td>\n      <td>0.750000</td>\n      <td>0.714286</td>\n      <td>0.714286</td>\n      <td>0.769231</td>\n      <td>0.740741</td>\n      <td>0.920000</td>\n      <td>0.851852</td>\n      <td>0.884615</td>\n      <td>0.802326</td>\n      <td>0.766667</td>\n      <td>0.784091</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.125100</td>\n      <td>0.762163</td>\n      <td>0.797753</td>\n      <td>0.797753</td>\n      <td>0.776154</td>\n      <td>0.798529</td>\n      <td>0.793478</td>\n      <td>0.811111</td>\n      <td>0.802198</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>0.642857</td>\n      <td>0.692308</td>\n      <td>0.666667</td>\n      <td>0.921569</td>\n      <td>0.870370</td>\n      <td>0.895238</td>\n      <td>0.766667</td>\n      <td>0.766667</td>\n      <td>0.766667</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.078000</td>\n      <td>0.840022</td>\n      <td>0.808989</td>\n      <td>0.808989</td>\n      <td>0.807021</td>\n      <td>0.809465</td>\n      <td>0.775510</td>\n      <td>0.844444</td>\n      <td>0.808511</td>\n      <td>0.833333</td>\n      <td>0.750000</td>\n      <td>0.789474</td>\n      <td>0.769231</td>\n      <td>0.769231</td>\n      <td>0.769231</td>\n      <td>0.940000</td>\n      <td>0.870370</td>\n      <td>0.903846</td>\n      <td>0.772727</td>\n      <td>0.755556</td>\n      <td>0.764045</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-100\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-100/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-100/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-100/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-100/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-200\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-200/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-200/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-200/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-200/special_tokens_map.json\nThe following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-300\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-300/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-300/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-300/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-300/special_tokens_map.json\nDeleting older checkpoint [xlm-roberta-industry-complete/checkpoint-100] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-400\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-400/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-400/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-400/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-400/special_tokens_map.json\nDeleting older checkpoint [xlm-roberta-industry-complete/checkpoint-200] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-500\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-500/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-500/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-500/special_tokens_map.json\nDeleting older checkpoint [xlm-roberta-industry-complete/checkpoint-300] due to args.save_total_limit\nThe following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-600\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-600/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-600/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-600/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-600/special_tokens_map.json\nDeleting older checkpoint [xlm-roberta-industry-complete/checkpoint-400] due to args.save_total_limit\nSaving model checkpoint to ./xlm-roberta-industry-complete/checkpoint-670\nConfiguration saved in ./xlm-roberta-industry-complete/checkpoint-670/config.json\nModel weights saved in ./xlm-roberta-industry-complete/checkpoint-670/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/checkpoint-670/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/checkpoint-670/special_tokens_map.json\nDeleting older checkpoint [xlm-roberta-industry-complete/checkpoint-500] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./xlm-roberta-industry-complete/checkpoint-600 (score: 0.8070212378811092).\nSaving model checkpoint to ./xlm-roberta-industry-complete\nConfiguration saved in ./xlm-roberta-industry-complete/config.json\nModel weights saved in ./xlm-roberta-industry-complete/model.safetensors\ntokenizer config file saved in ./xlm-roberta-industry-complete/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/special_tokens_map.json\ntokenizer config file saved in ./xlm-roberta-industry-complete/tokenizer_config.json\nSpecial tokens file saved in ./xlm-roberta-industry-complete/special_tokens_map.json\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Evaluate on test set\nlogger.info(\"Evaluating on test set...\")\nprint(\"Evaluating on test set...\")\ntest_results = trainer.evaluate(\n    tokenized_datasets[\"test\"],\n    metric_key_prefix=\"test\"\n)\n\n# Save evaluation results\nwith open(os.path.join(config.OUTPUT_DIR, 'test_results.txt'), 'w') as f:\n    for key, value in test_results.items():\n        f.write(f\"{key}: {value}\\n\")\n\nlogger.info(\"\\n=== Test Results ===\")\nprint(\"\\n=== Test Results ===\")\nfor key, value in test_results.items():\n    if key.startswith(\"test_\"):\n        logger.info(f\"{key[5:]}: {value}\")\n        print(f\"{key[5:]}: {value}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:24:21.183383Z","iopub.execute_input":"2025-07-24T14:24:21.183636Z","iopub.status.idle":"2025-07-24T14:24:25.025668Z","shell.execute_reply.started":"2025-07-24T14:24:21.183614Z","shell.execute_reply":"2025-07-24T14:24:25.025112Z"}},"outputs":[{"name":"stderr","text":"The following columns in the Evaluation set don't have a corresponding argument in `XLMRobertaForSequenceClassification.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `XLMRobertaForSequenceClassification.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 267\n  Batch size = 16\n","output_type":"stream"},{"name":"stdout","text":"Evaluating on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17/17 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"early stopping required metric_for_best_model, but did not find eval_f1_macro so early stopping is disabled\n","output_type":"stream"},{"name":"stdout","text":"\n=== Test Results ===\nloss: 1.0174436569213867\naccuracy: 0.8089887640449438\nf1_micro: 0.8089887640449437\nf1_macro: 0.7739784481623146\nf1_weighted: 0.8092312359790224\nfinance_precision: 0.8444444444444444\nfinance_recall: 0.8539325842696629\nfinance_f1: 0.8491620111731844\ntechnology_precision: 0.5\ntechnology_recall: 0.5238095238095238\ntechnology_f1: 0.5116279069767442\nhealthcare_precision: 0.7857142857142857\nhealthcare_recall: 0.8461538461538461\nhealthcare_f1: 0.8148148148148148\nenergy_precision: 0.9259259259259259\nenergy_recall: 0.9259259259259259\nenergy_f1: 0.9259259259259259\nother_precision: 0.7816091954022989\nother_recall: 0.7555555555555555\nother_f1: 0.768361581920904\nruntime: 3.829\nsamples_per_second: 69.732\nsteps_per_second: 4.44\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Sample predictions function\ndef predict_industry(text):\n    inputs = tokenizer(\n        text,\n        max_length=config.MAX_LENGTH,\n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\"\n    ).to(trainer.model.device)\n    \n    with torch.no_grad():\n        outputs = trainer.model(**inputs)\n    \n    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n    pred_class = torch.argmax(probs).item()\n    \n    return {\n        \"industry\": config.REVERSE_INDUSTRY_MAP[pred_class],\n        \"confidence\": probs[0][pred_class].item(),\n        \"probabilities\": {\n            \"Finance\": probs[0][0].item(),\n            \"Technology\": probs[0][1].item(),\n            \"Healthcare\": probs[0][2].item(),\n            \"Energy\": probs[0][3].item(),\n            \"Other\": probs[0][4].item()\n        }\n    }\n\n# Test on some samples and save predictions\nsample_texts = df.sample(5, random_state=config.SEED)[\"summary\"].tolist()\nwith open(os.path.join(config.OUTPUT_DIR, 'sample_predictions.txt'), 'w') as f:\n    for i, text in enumerate(sample_texts):\n        result = predict_industry(text)\n        actual = df[df['summary'] == text]['industry'].values[0]\n        \n        f.write(f\"\\n=== Sample {i+1} ===\\n\")\n        f.write(f\"\\nText: {text}\\n\")\n        f.write(f\"\\nPredicted Industry: {result['industry']} (Confidence: {result['confidence']:.2f})\\n\")\n        f.write(f\"Probabilities: {result['probabilities']}\\n\")\n        f.write(f\"Actual Industry: {actual}\\n\")\n        \n        logger.info(f\"Sample {i+1} - Predicted: {result['industry']}, Actual: {actual}\")\n        print(f\"\\n=== Sample {i+1} ===\")\n        print(f\"\\nText: {text}\")\n        print(f\"\\nPredicted Industry: {result['industry']} (Confidence: {result['confidence']:.2f})\")\n        print(f\"Probabilities: {result['probabilities']}\")\n        print(f\"Actual Industry: {actual}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:24:25.026427Z","iopub.execute_input":"2025-07-24T14:24:25.026612Z","iopub.status.idle":"2025-07-24T14:24:38.660517Z","shell.execute_reply.started":"2025-07-24T14:24:25.026597Z","shell.execute_reply":"2025-07-24T14:24:38.659717Z"}},"outputs":[{"name":"stdout","text":"\n=== Sample 1 ===\n\nText: Giá điện sinh hoạt đang bù chéo cho sản xuất, gây \"méo mó\" thị trường, đi ngược Nghị quyết 55. Người dân đang phải trả giá cao hơn để bù cho doanh nghiệp, đặc biệt FDI. Luật Điện lực sửa đổi mới chỉ quy định giảm dần bù chéo. Chuyên gia kiến nghị xóa bỏ bù chéo, cần cải cách giá điện theo cơ chế thị trường, minh bạch chi phí. Cần đẩy nhanh giá điện 2 thành phần, khuyến khích đầu tư tư nhân, nước ngoài vào ngành điện.\n\n\nPredicted Industry: Energy (Confidence: 1.00)\nProbabilities: {'Finance': 0.0009795400546863675, 'Technology': 0.0008036752115003765, 'Healthcare': 0.0008965007727965713, 'Energy': 0.9966979026794434, 'Other': 0.0006224566022865474}\nActual Industry: Energy\n\n=== Sample 2 ===\n\nText: HoSE xem xét hủy niêm yết bắt buộc cổ phiếu KPF do vi phạm công bố thông tin và chậm nộp BCTC. KPF đang bị đình chỉ giao dịch, cảnh báo, kiểm soát vì chậm nộp BCTC soát xét, có ý kiến ngoại trừ và chậm nộp BCTC kiểm toán. KPF xin gia hạn công bố BCTC do khó khăn đối chiếu số liệu, nhưng UBCKNN từ chối vì không thuộc trường hợp bất khả kháng. Quý I/2025, KPF không có doanh thu và lỗ ròng hơn 50 triệu đồng. Tổng tài sản KPF là 532,6 tỷ đồng, chủ yếu là đầu tư tài chính dài hạn, nợ phải trả gần 16,9 tỷ đồng.\n\n\nPredicted Industry: Finance (Confidence: 1.00)\nProbabilities: {'Finance': 0.9952011108398438, 'Technology': 0.0006774133653379977, 'Healthcare': 0.001101412228308618, 'Energy': 0.0017376895993947983, 'Other': 0.0012823316501453519}\nActual Industry: Finance\n\n=== Sample 3 ===\n\nText: Nghị quyết 42 hết hiệu lực gây khó khăn cho việc thu hồi nợ xấu, hiện ở mức 1,064 triệu tỉ đồng và tiếp tục tăng. Tỉ lệ khách hàng tự nguyện trả nợ thấp, nguồn xử lý nợ xấu chủ yếu từ dự phòng rủi ro của các tổ chức tín dụng, ảnh hưởng đến kết quả kinh doanh và hỗ trợ doanh nghiệp. Việc thu hồi nợ gặp khó khăn do tài sản đảm bảo phức tạp, tranh chấp. Các ngân hàng đề xuất luật hóa nghị quyết 42 để chủ động thu giữ tài sản đảm bảo, giảm thời gian và chi phí kiện tụng. Cần có quy định pháp luật rõ ràng để đảm bảo quyền lợi của các bên, yêu cầu người vay phải có trách nhiệm trả nợ.\n\n\nPredicted Industry: Finance (Confidence: 1.00)\nProbabilities: {'Finance': 0.995909571647644, 'Technology': 0.0006906886701472104, 'Healthcare': 0.0010050623677670956, 'Energy': 0.001177375321276486, 'Other': 0.0012172964634373784}\nActual Industry: Finance\n\n=== Sample 4 ===\n\nText: PV Power tổ chức sự kiện thường niên tăng cường quan hệ nhà đầu tư, giới thiệu hoạt động kinh doanh và chủ trương phát triển. 10 tháng đầu năm 2024, PV Power đạt 76% kế hoạch sản lượng điện, 77,74% doanh thu và vượt 136% kế hoạch lợi nhuận sau thuế. PV Power tập trung vận hành an toàn, hiệu quả để hoàn thành kế hoạch năm 2024. Dự án nhà máy điện Nhơn Trạch 3 dự kiến vận hành tháng 6/2025, Nhơn Trạch 4 tháng 9/2025. Khách mời đã tham quan dự án Nhơn Trạch 3&4 và tìm hiểu nhà máy Nhơn Trạch 2.\n\n\nPredicted Industry: Energy (Confidence: 1.00)\nProbabilities: {'Finance': 0.0009315177449025214, 'Technology': 0.0011576353572309017, 'Healthcare': 0.0006239776848815382, 'Energy': 0.9967185854911804, 'Other': 0.0005683077615685761}\nActual Industry: Energy\n\n=== Sample 5 ===\n\nText: Đại biểu Quốc hội băn khoăn về việc doanh nghiệp nhà nước đầu tư ngoài ngành, đặc biệt vào bất động sản, lo ngại thất thoát và rủi ro pháp lý. Một số ý kiến cho rằng cần cân nhắc kỹ, không nên cho phép tất cả doanh nghiệp nhà nước đầu tư bất động sản, mà nên xem xét theo điều kiện cụ thể. Hiệp hội doanh nghiệp vừa và nhỏ đề xuất ưu tiên doanh nghiệp nhà nước trong các lĩnh vực an sinh xã hội, quốc phòng, nhưng cần có sự giao việc cụ thể để tránh rủi ro khi \"nhảy\" vào lĩnh vực có lợi nhuận cao như bất động sản. Bộ Tài chính cho biết dự luật sửa đổi theo hướng Nhà nước không can thiệp trực tiếp vào hoạt động sản xuất, kinh doanh của doanh nghiệp, mà chỉ quản lý phần vốn nhà nước. Dự luật bổ sung quy định tăng phân cấp, phân quyền cho chủ sở hữu vốn nhà nước, khuyến khích doanh nghiệp tăng trưởng, đổi mới sáng tạo.\n\n\nPredicted Industry: Finance (Confidence: 0.99)\nProbabilities: {'Finance': 0.9940699934959412, 'Technology': 0.000770478683989495, 'Healthcare': 0.0010611003963276744, 'Energy': 0.0011220143642276525, 'Other': 0.0029763851780444384}\nActual Industry: Finance\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Create zip file of all outputs\ndef zip_output_folder(output_dir):\n    zip_path = os.path.join(output_dir, 'output.zip')\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(output_dir):\n            for file in files:\n                if file != 'output.zip':\n                    file_path = os.path.join(root, file)\n                    arcname = os.path.relpath(file_path, output_dir)\n                    zipf.write(file_path, arcname)\n    return zip_path\n\noutput_zip = zip_output_folder(config.OUTPUT_DIR)\nlogger.info(f\"Created zip file at: {output_zip}\")\n\nprint(\"Training complete! Download the results:\")\nfrom IPython.display import FileLink\nFileLink(output_zip)\n\nlogger.info(\"Training process completed successfully\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T14:24:38.661336Z","iopub.execute_input":"2025-07-24T14:24:38.661592Z","iopub.status.idle":"2025-07-24T14:33:08.494626Z","shell.execute_reply.started":"2025-07-24T14:24:38.661567Z","shell.execute_reply":"2025-07-24T14:33:08.493935Z"}},"outputs":[{"name":"stdout","text":"Training complete! Download the results:\n","output_type":"stream"}],"execution_count":14}]}